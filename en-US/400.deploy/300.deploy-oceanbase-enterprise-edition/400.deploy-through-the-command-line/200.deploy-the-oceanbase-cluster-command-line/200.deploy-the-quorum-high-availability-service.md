|description||
|---|---|
|keywords||
|dir-name||
|dir-name-en||
|tenant-type||

# Deploy a two-replica OceanBase cluster with the arbitration service by using the CLI

OceanBase Database supports the arbitration service since V4.1. The arbitration service can resolve the issue that the response time increases when a replica in the same region fails in the deployment scenario of three IDCs across two regions. The arbitration service can also reduce the cross-region bandwidth overhead and minimize the costs of the third IDC.

This topic describes how to deploy a two-node OceanBase cluster and an arbitration service by using the command-line interface (CLI).

<main id="notice" type='explain'>
  <h4>Note</h4>
  <p><ul><li>A single OceanBase cluster can use only one arbitration service. </li><li>Currently, an arbitration service supports only standalone deployment. </li></ul></p>
</main>

## Considerations

If you want to implement resource isolation for your OceanBase database, configure cgroups before the deployment.

For more information about resource isolation and cgroup, see [Resource isolation](../../../../600.manage/200.tenant-management/600.common-tenant-operations/300.resource-isolation/100.resource-isolation-overview.md) and [Configure cgroups](../../../../600.manage/200.tenant-management/600.common-tenant-operations/300.resource-isolation/200.resource-isolation-of-oracle-mode/100.config-cgroups-of-oracle-mode.md).

## Prerequisites

Before you install OceanBase Database, make sure that:

* The OBServer node has been configured. For more information, see [Configure servers](../../200.preparations-before-deploy/200.configure-servers.md), [(Optional) Configure the clock source](../100.configure-a-deployment-environment-command-line/200.configure-host-information.md), and [Initialize an OBServer node by using oatcli](../100.configure-a-deployment-environment-command-line/100.initializing-the-observer-server-using-oatcli.md).

* You have obtained the RPM package of OceanBase Database. For more information, see [Prepare installation packages](../../200.preparations-before-deploy/300.prepare-installation-packages.md).

## Procedure

### Step 1: Deploy an OceanBase cluster

1. Install the RPM package on the two servers that you want to deploy OceanBase Database.

   1. Install the RPM package for OceanBase Database.

      Go to the directory where the RPM package of OceanBase Database is saved.

      ```shell
      [root@xxx /]# cd $rpm_dir
      ```

      Install the RPM package of OceanBase Database.

      ```shell
      [root@xxx $rpm_dir]# rpm -ivh $rpm_name [--prefix=/home/admin/oceanbase]
      ```

      Here, `$rpm_dir` specifies the directory in which the RPM package is stored, and `$rpm_name` specifies the name of the RPM package.

        <main id="notice" type='explain'>
            <h4>Note</h4>
            <p>The OceanBase Database software will be installed under the <code>/home/admin/oceanbase</code> directory. </p>
        </main>

      Here is an example:

      ```shell
      [root@xxx /home/admin/rpm]# rpm -ivh oceanbase-4.2.0.0-100000052023073123.el7.x86_64.rpm
      Preparing...                          ################################# [100%]
      Updating / installing...
          1:oceanbase-4.2.0.0-100000052023073################################# [100%]
      ```

   2. (Optional) Install OceanBase Client (OBClient).

      OBClient is a CLI tool dedicated to OceanBase Database. You can use it to connect to MySQL tenants and Oracle tenants of OceanBase Database. If you only need to connect to a MySQL tenant, you can also use a MySQL client to access OceanBase Database.

         <main id="notice" type='notice'>
         <h4>Notice</h4>
         <p>In order to use versions of OBClient earlier than V2.2.1, install OceanBase Connector/C due to the dependency on OceanBase Connector/C. To obtain the RPM packages of OBClient and OceanBase Connector/C, contact OceanBase Technical Support. </p>
         </main>

      Here is an example:

      ```shell
      [root@xxx /home/admin/rpm]# rpm -ivh obclient-2.2.1-20221122151945.el7.alios7.x86_64.rpm
      Preparing...                          ################################# [100%]
      Updating / installing...
         1:obclient-2.2.1-20221122151945.el7################################# [100%]
      ```

      Verify that the installation is successful.

      ```shell
      [root@xxx /home/admin/rpm]# which obclient
      /usr/bin/obclient
      ```

2. Configure the observer process directory.

   1. (Optional) Clear the OceanBase Database directory.

      You do not need to clear the directory if you deploy OceanBase Database on the server for the first time.

      You can directly clear the old OceanBase Database directory in the following cases:

      * You want to clear the old OceanBase Database environment.
      * Problems occur during the installation and deployment process of OceanBase Database. The installation environment becomes disordered or files that will affect the next installation are generated.

      ```shell
      [root@xxx /home/admin]# kill -9 `pidof observer`
      [root@xxx /home/admin]# rm -rf /data/1/$cluster_name
      [root@xxx /home/admin]# rm -rf /data/log1/$cluster_name
      [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/store/$cluster_name
      [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/log/* /home/admin/oceanbase/etc/*config*
      ```

      Here, `$cluster_name` specifies the cluster name.

      Here is an example:

      ```shell
      [root@xxx /home/admin]# kill -9 `pidof observer`
      [root@xxx /home/admin]# rm -rf /data/1/obdemo
      [root@xxx /home/admin]# rm -rf /data/log1/obdemo
      [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/store/obdemo
      [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/log/* /home/admin/oceanbase/etc/*config*
      ```

   2. Initialize the OceanBase Database directory.

      We recommend that you specify the data directory of OceanBase Database to an independent disk and link this directory to the home directory of OceanBase Database by using a soft link.

      <main id="notice" type='explain'>
         <h4>Note</h4>
         <p>Starting from V4.3.0, OceanBase Database supports an independent <code>slog</code> disk so that <code>slog</code> files do not need to share a disk with data files. <code>slog</code> files and <code>clog</code> files can share an SSD. For more information about the installation directory of OceanBase Database, see <a href="../../../../700.reference/100.oceanbase-database-concepts/1200.observer-node-architecture/100.observer-installation-directory-structure.md">Structure of the OBServer node installation directory</a>. </p>
      </main>

      Run the following command to switch to the `admin` user:

      ```shell
      [root@xxx /home/admin]# su - admin
      ```

      Run the following commands as the `admin` user to create the related directories:

      ```shell
      mkdir -p /data/1/$cluster_name/{etc3,sstable,slog}
      ```

      ```shell
      mkdir -p /data/log1/$cluster_name/{clog,etc2}
      ```

      ```shell
      mkdir -p /home/admin/oceanbase/store/$cluster_name
      ```

      Run the following commands as the `admin` user to create soft links:

      ```shell
      for t in {etc3,sstable,slog};do ln -s /data/1/$cluster_name/$t /home/admin/oceanbase/store/$cluster_name/$t; done
      ```

      ```shell
      for t in {clog,etc2};do ln -s /data/log1/$cluster_name/$t /home/admin/oceanbase/store/$cluster_name/$t; done
      ```

      Here, `$cluster_name` specifies the cluster name.

      Here is an example:

      ```shell
      [root@xxx /home/admin]# su - admin
      -bash-4.2$ mkdir -p /data/1/obdemo/{etc3,sstable,slog}
      -bash-4.2$ mkdir -p /data/log1/obdemo/{clog,etc2}
      -bash-4.2$ mkdir -p /home/admin/oceanbase/store/obdemo
      -bash-4.2$ for t in {etc3,sstable,slog};do ln -s /data/1/obdemo/$t /home/admin/oceanbase/store/obdemo/$t; done
      -bash-4.2$ for t in {clog,etc2};do ln -s /data/log1/obdemo/$t /home/admin/oceanbase/store/obdemo/$t; done
      ```

      <main id="notice" type='explain'>
         <h4>Note</h4>
         <p>The <code>obdemo</code> directory is named after the cluster and can be modified. It is required when the process starts. </p>
      </main>

      The result is as follows:

      ```shell
      -bash-4.2$ cd /home/admin/oceanbase
      -bash-4.2$ tree store/
      store/
      `-- obdemo
         |-- clog -> /data/log1/obdemo/clog
         |-- etc2 -> /data/log1/obdemo/etc2
         |-- etc3 -> /data/1/obdemo/etc3
         |-- slog -> /data/1/obdemo/slog
         `-- sstable -> /data/1/obdemo/sstable

      6 directories, 0 files
      ```

3. Initialize the OceanBase cluster.

    <main id="notice" type='explain'>
      <h4>Note</h4>
      <p><ul><li>The IP addresses in the sample code are for reference only. You need to enter the actual server IP address during deployment. </li><li>OceanBase Database allows you to start the observer process on a server with a specified IPv4 or IPv6 address. This topic describes how to start the observer process on a server with an IPv4 address. For information about how to start the observer process on a server with an IPv6 address, see <a href="100.stand-alone-deployment-of-oceanbase-database.md">Deploy a standalone OceanBase database by using the CLI</a>. </li></ul></p>
    </main>

   1. Start the observer process.

      Start the observer process as the `admin` user on each node.

        <main id="notice" type='notice'>
        <h4>Notice</h4>
        <p>In a two-replica OceanBase cluster, the startup parameters of the OBServer nodes are not exactly the same. When you start the observer process, you only need to specify the two or more servers that run RootService. You can add servers after the cluster is created. </p>
        </main>

      ```shell
      cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer {-I $ip | -i $devname} -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r '$ip:2882:2881' -c $cluster_id -n $cluster_name -o "system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2"
      ```

      The parameters are described in the following table.

      | **Parameter** | **Description** |
      |--------|----------------------------|
      | `-I` \| `-i` | <ul><li>`-I`: the IP address of the node to be started. In multi-node deployment, you cannot use 127.0.0.1 as the destination IP address. We recommend that you use an IP address such as `-I 10.10.10.1`, to start a node. </li><li>`-i`: the NIC name. You can use the `ifconfig` command to view the NIC name. </li></ul><main id="notice" type='explain'><h4>Note</h4><p>OceanBase Database allows you to start a node by specifying both the IP address and the NIC. For example, `-I 10.10.10.1 -i eth0`. However, we recommend that you do not use this method. </p></main> |
      | `-p` | The service port number, which is usually set to `2881`.  |
      | `-P` | The RPC port number, which is usually set to `2882`.  |
      | `-n` | The name of the cluster. It can be modified. Cluster names must be unique.  |
      | `-z` | The zone to which the started observer process belongs.  |
      | `-d` | The primary directory of the cluster, which is created during initialization. Do not modify fields other than `$cluster_name`.  |
      | `-c` | The cluster ID. It is a group of digits and can be modified. Cluster IDs must be unique.  |
      | `-l` | The log level.  |
      | `-r` | The RootService list in the format of `$ip:2882:2881`. Multiple items are separated with semicolons (;) to indicate RootService information.  |
      | `-o` | Optional. The cluster startup parameters. You can specify values for multiple parameters and separate the settings of different parameters with commas (,). We recommend that you set appropriate values for cluster startup parameters to optimize cluster performance and resource utilization. Here are some commonly used cluster startup parameters:<ul><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/3700.cpu_count.md">cpu_count</a>: the total number of system CPU cores. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/22400.system_memory.md">system_memory</a>: the memory reserved for the tenant whose ID is <code>500</code>, that is, the internal reserved memory of OceanBase Database. If the machine has a small memory size, you can set this parameter to a smaller value. However, insufficient memory may occur during performance testing. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/13500.memory_limit.md">memory_limit</a>: the total memory size available. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/4700.datafile_size.md">datafile_size</a>: the size of disk space available for data files. That is, the size of the data file <code>sstable</code> (for one-time initialization) in OceanBase Database. You can evaluate the value of this parameter based on the available space on <code>/data/1/</code>. We recommend that the value is no less than <code>100G</code>. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/4400.datafile_disk_percentage.md">datafile_disk_percentage</a>: the percentage of total disk space allowed for data files. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/4600.datafile_next.md">datafile_next</a>: the step size of automatic scale-out for disk files. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/4500.datafile_maxsize.md">datafile_maxsize</a>: the maximum size of disk space allowed for automatic scale-out of data files. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/3600.config_additional_dir.md">config_additional_dir</a>: the local directories for storing multiple copies of configuration files for redundancy. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/12700.log_disk_size.md">log_disk_size</a>: the size of the log disk where REDO logs are stored. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/12600.log_disk_percentage.md">log_disk_percentage</a>: the percentage of total disk space occupied by REDO logs. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/22200.syslog_level.md">syslog_level</a>: the level of system logs. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/22100.syslog_io_bandwidth_limit.md">syslog_io_bandwidth_limit</a>: the maximum I/O bandwidth available for system logs. If this value is reached, the remaining system logs are discarded. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/13300.max_syslog_file_count.md">max_syslog_file_count</a>: the maximum number of log files that can be retained. </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/9000.enable_syslog_recycle.md">enable_syslog_recycle</a>: specifies whether to enable system log recycling. </li></ul> You can configure <code>datafile_size</code>, <code>datafile_disk_percentage</code>, <code>datafile_next</code>, and <code>datafile_maxsize</code> together to achieve automatic scale-out of disk space for data files. For more information, see <a href="../../../../700.reference/200.system-management/1000.disk-data-file-management/100.disk-data-file-dynamic-expansion.md">Configure automatic scale-out of disk space for data files</a>. For more information about cluster configuration, see <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/200.system-configuration-items-overview-list.md">Cluster-level parameters</a>.  |

      Here is an example:

      Start the observer process on the OBServer nodes whose IP addresses are `10.10.10.1` and `10.10.10.2` respectively.

      **zone1:**

      ```shell
      [root@xxx admin]# su - admin
      -bash-4.2$ cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer -I 10.10.10.1 -P 2882 -p 2881 -z zone1 -d /home/admin/oceanbase/store/obdemo -r '10.10.10.1:2882:2881;10.10.10.2:2882:2881' -c 10001 -n obdemo -o "system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/obdemo/etc3;/data/log1/obdemo/etc2"
      ```

      **zone2:**

      ```shell
      [root@xxx admin]# su - admin
      -bash-4.2$ cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer -I 10.10.10.2 -P 2882 -p 2881 -z zone2 -d /home/admin/oceanbase/store/obdemo -r '10.10.10.2:2882:2881;10.10.10.2:2882:2881' -c 10001 -n obdemo -o "system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/obdemo/etc3;/data/log1/obdemo/etc2"
      ```

      You can use the following commands to check whether the observer process has started successfully:

      * Run the `netstat -ntlp` command. If ports `2881` and `2882` are listened to, the observer process is started.
      * Run the `ps -ef|grep observer` command to return information about the observer process.

      Here is an example:

      ```shell
      -bash-4.2$ netstat -ntlp
      (Not all processes could be identified, non-owned process info
      will not be shown, you would have to be root to see it all.)
      Active Internet connections (only servers)
      Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
      tcp        0      0 0.0.0.0:2881            0.0.0.0:*               LISTEN      11112/observer
      tcp        0      0 0.0.0.0:2882            0.0.0.0:*               LISTEN      11112/observer
      ...        ...    ...                       ...                     ...         ...

      -bash-4.2$ ps -ef|grep observer
      admin     11112      0 40 16:18 ?        00:00:17 /home/admin/oceanbase/bin/observer -I 10.10.10.1 -P 2882 -p 2881 -z zone1 -d /home/admin/oceanbase/store/obdemo -r 10.10.10.1:2882:2881;10.10.10.2:2882:2881 -c 10001 -n obdemo -o system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/obdemo/etc3;/data/log1/obdemo/etc2
      ```

   2. Perform the bootstrap operation on the cluster.

      Connect to any node by using the obclient command. The password is empty.

      ```shell
      [root@xxx admin]# obclient -h127.0.0.1 -uroot -P2881 -p******

      obclient [(none)]> SET SESSION ob_query_timeout=1000000000;
      Query OK, 0 rows affected

      obclient [(none)]> ALTER SYSTEM BOOTSTRAP ZONE 'zone1' SERVER '10.10.10.1:2882',ZONE 'zone2' SERVER '10.10.10.2:2882';
      Query OK, 0 rows affected
      ```

        <main id="notice" type='notice'>
        <h4>Notice</h4>
        <p>If an error is reported in this step, the reason may be that the startup parameter of the observer process is incorrect, the privileges on the directories related to the OBServer nodes are incorrect, the space of the log directory does not meet the required proportion, the time is not synchronous on the OBServer nodes, or the node memory resources are insufficient. The log directory issue occurs because the log directory shares the same upper-level directory with the data directory, resulting in space occupation by the data directory. Check these issues and then clear the OceanBase Database directory. </p>
        </main>

   3. Verify that the cluster is initialized.

      After you perform the bootstrap operation and execute the `SHOW DATABASES` statement, if `oceanbase` appears in the database list, the cluster has been initialized.

      ```bash
      obclient [(none)]> SHOW DATABASES;
      +--------------------+
      | Database           |
      +--------------------+
      | information_schema |
      | LBACSYS            |
      | mysql              |
      | oceanbase          |
      | ORAAUDITOR         |
      | SYS                |
      | test               |
      +--------------------+
      7 rows in set
      ```

   4. Change the password.

      By default, the password of the root user under the `sys` tenant is empty. After successful initialization, you need to change the password.

      ```sql
      obclient [(none)]> ALTER USER root IDENTIFIED BY '******';
      Query OK, 0 rows affected
      ```

### Step 2: Deploy the arbitration service

1. Install the RPM package of OceanBase Database on the server that you want to deploy the arbitration service.

   Go to the directory where the RPM package of OceanBase Database is saved.

   ```shell
   [root@xxx /]# cd $rpm_dir
   ```

   Install the RPM package of OceanBase Database.

   ```shell
   [root@xxx $rpm_dir]# rpm -ivh $rpm_name [--prefix=/home/admin/oceanbase]
   ```

   Here, `$rpm_dir` specifies the directory in which the RPM package is stored, and `$rpm_name` specifies the name of the RPM package.

   <main id="notice" type='explain'>
      <h4>Note</h4>
      <p>The OceanBase Database software will be installed under the <code>/home/admin/oceanbase</code> directory. </p>
   </main>

   Here is an example:

   ```shell
   [root@xxx /home/admin/rpm]# rpm -ivh oceanbase-4.2.0.0-100000052023073123.el7.x86_64.rpm
   Preparing...                          ################################# [100%]
   Updating / installing...
      1:oceanbase-4.2.0.0-100000052023073################################# [100%]
   ```

2. Configure the arbitration server process directory.

   Create the `clog` directory for the arbitration server process in the arbitration server.

    <main id="notice" type='explain'>
      <h4>Note</h4>
      <p><ul><li>When you start the arbitration server process, make sure that the <code>clog</code> directory is created in the <code>store</code> directory specified by the <code>-d</code> parameter. </li><li>Make sure that the disk where the <code>store</code> directory resides is not fully occupied. Otherwise, the arbitration server may be abnormal. </li></ul></p>
    </main>

   Run the following command to switch to the `admin` user:

   ```shell
   [root@xxx /home/admin]# su - admin
   ```

   Run the following command as the `admin` user to create the related directory:

   ```shell
   mkdir -p /home/admin/oceanbase/store/clog
   ```

3. Start the arbitration server process.

   Start the arbitration server process in arbitration mode as the `admin` user of the arbitration server and specify the required startup parameters. Here is the sample statement:

   ```shell
   cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer -m arbitration -P $rpc_port -d $obdir/store [{-I $ip | -i $devname}] [-l $log_level]  [-o "parameters_list"]
   ```

   The parameters are described in the following table.

   | **Parameter** | **Description** |
   |----------|-------------|
   | `-m` | The arbitration mode. The value is `arbitration`.  |
   | `-P` | The RPC port number of the arbitration server process, which is usually set to `2882`.  |
   | `-d` | The path for the `store` directory, which is usually set to `/home/admin/oceanbase/store`. Make sure that the `clog` folder is created in the `store` directory.  |
   | `-I` \| `-i` | Optional. <ul><li>`-I`: the IP address of the node to be started. </li><li>`-i`: the NIC name. You can use the `ifconfig` command to view the NIC name. </li></ul><main id="notice" type='explain'><h4>Note</h4><p>OceanBase Database allows you to start a node by specifying both the IP address and the NIC. For example, `-I 10.10.10.1 -i eth0`. However, we recommend that you do not use this method. </p></main> |
   | `-l` | The log level. Optional. Default value: `WDIAG`. Valid values: {`DEBUG`, `TRACE`, `WDIAG`, `EDIAG`, `INFO`, `WARN`, and `ERROR`}. For more information, see [Log levels](../../../../600.manage/800.logging/200.log-level.md).  |
   | `-o` | Optional. The list of options. You can specify multiple options and separate them with commas (,). Here are the common startup parameters of the arbitration server process:<ul><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/3700.cpu_count.md">cpu_count</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/22400.system_memory.md">system_memory</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/13500.memory_limit.md">memory_limit</a> </li><li> <a href="../../../../700.reference/1000.performance-tuning-guide/300.system-tuning/200.database-parameter-tuning/400.network-transmission-parameters.md">__easy_memory_limit</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/12700.log_disk_size.md">log_disk_size</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/12600.log_disk_percentage.md">log_disk_percentage</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/22200.syslog_level.md">syslog_level</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/22100.syslog_io_bandwidth_limit.md">syslog_io_bandwidth_limit</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/13300.max_syslog_file_count.md">max_syslog_file_count</a> </li><li> <a href="../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/300.cluster-level-configuration-items/9000.enable_syslog_recycle.md">enable_syslog_recycle</a> </li></ul>  <main id="notice" type='notice'><h4>Notice</h4><p>To prevent the disk from being fully occupied by the log directory of the arbitration service node, you need to set <code>enable_syslog_recycle</code> to <code>True</code> to enable automatic cleanup and set <code>max_syslog_file_count</code> to a valid value. Otherwise, the log file will continue to expand and may use up the disk space. </p></main> |

   Here is an example:

   Start the arbitration server process on the arbitration server whose IP address is `10.10.10.3`.

   ```shell
   -bash-4.2$ cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer -m arbitration -P 2882 -d /home/admin/oceanbase/store -I 10.10.10.3 -o "enable_syslog_recycle=True,max_syslog_file_count=100"
   ```

   You can use the following commands to check whether the observer process has started successfully:

   * Run the `netstat -ntlp` command. If the `2882` port is being listened to, the process is started successfully.
   * Run the `ps -ef|grep observer` command to return information about the observer process.

   Here is an example:

   ```shell
   -bash-4.2$ netstat -ntlp
   (Not all processes could be identified, non-owned process info
   will not be shown, you would have to be root to see it all.)
   Active Internet connections (only servers)
   Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
   tcp        0      0 0.0.0.0:2882            0.0.0.0:*               LISTEN      18231/observer
   ...

   -bash-4.2$ ps -ef|grep observer
   admin     18231      0  3 10:33 ?        00:00:00 /home/admin/oceanbase/bin/observer -m arbitration -P 2882 -d /home/admin/oceanbase/store -I 10.10.10.3
   ...
   ```

### Step 3: Add the arbitration service to the cluster

Run the following command to add the arbitration service to a cluster:

```sql
ALTER SYSTEM ADD ARBITRATION SERVICE "$arb_server_ip:$arb_server_port";
```

<main id="notice" type='explain'>
   <h4>Note</h4>
   <p>The address of the arbitration server process is recorded in an internal table in the <code>sys</code> tenant. You can view the process address in the <code>DBA_OB_ARBITRATION_SERVICE</code> view. </p>
</main>

Here is an example:

```shell
obclient [(none)]> ALTER SYSTEM ADD ARBITRATION SERVICE "10.10.10.3:2882";
Query OK, 0 rows affected

obclient [(none)]> SELECT * FROM oceanbase.DBA_OB_ARBITRATION_SERVICE;
+---------------------+---------------------+-------------------------+---------------------+------------------------------+------+
| CREATE_TIME         | MODIFY_TIME         | ARBITRATION_SERVICE_KEY | ARBITRATION_SERVICE | PREVIOUS_ARBITRATION_SERVICE | TYPE |
+---------------------+---------------------+-------------------------+---------------------+------------------------------+------+
| 2023-03-06 17:29:36 | 2023-03-06 17:29:36 | default                 | 10.10.10.3:2882     | NULL                         | ADDR |
+---------------------+---------------------+-------------------------+---------------------+------------------------------+------+
1 row in set
```

### Step 4: Enable the arbitration service for the sys tenant

You can enable the arbitration service for a tenant when you create the tenant. For more information, see [CREATE TENANT](../../../../700.reference/500.sql-reference/100.sql-syntax/100.system-tenants/800.create-tenant.md).

If you do not enable the arbitration service when you create the tenant, you can still enable it after the tenant is created.

Execute the following statement to enable the arbitration service for a tenant:

```sql
ALTER TENANT $tenant_name [SET] enable_arbitration_service = true;
```

Here is an example:

Enable the arbitration service for the `sys` tenant of the cluster.

```shell
obclient [(none)]> ALTER TENANT sys SET enable_arbitration_service = true;
Query OK, 0 rows affected
```

### Step 5: Query the status of the arbitration service in the tenant

1. Check whether the arbitration service is enabled for the tenant.

   You can check whether the arbitration service is enabled for the tenant by querying the `arbitration_service_status` column of the `DBA_OB_TENANTS` view.

   Values of `arbitration_service_status` are described as follows:

   * `ENABLED`: The arbitration service is enabled for the tenant.
   * `ENABLING`: The arbitration service is being enabled for the tenant.
   * `DISABLED`: The arbitration service is disabled for the tenant.
   * `DISABLING`: The arbitration service is being disabled for the tenant.

   Here is an example:

   ```shell
   obclient [(none)]> SELECT TENANT_ID,TENANT_NAME,ARBITRATION_SERVICE_STATUS FROM oceanbase.DBA_OB_TENANTS WHERE tenant_name = 'sys';
   +-----------+-------------+----------------------------+
   | TENANT_ID | TENANT_NAME | ARBITRATION_SERVICE_STATUS |
   +-----------+-------------+----------------------------+
   |         1 | sys         | ENABLED                    |
   +-----------+-------------+----------------------------+
   1 row in set
   ```

2. Check whether the arbitration service is available.

   After you enable the arbitration service, the existing log streams of the tenant can use the arbitration service, but the new log streams created afterward may not be able to use it. This is because a log stream is created in non-strict mode. In this mode, it is possible that the arbitration service may fail to be created. You can execute the following statement to verify whether all log streams of the tenant can use the arbitration service.

   ```shell
   ## Obtain a list of log streams that do not have an arbitration member. ##
   (SELECT distinct ls_id FROM GV$OB_LOG_STAT WHERE tenant_id = xxx) except
   (SELECT ls_id FROM GV$OB_LOG_STAT WHERE tenant_id = xxx and role = 'LEADER' and arbitration_member = "$arb_server_ip:$arb_server_port");
   ```

   Here is an example:

   Obtain a list of log streams that do not have arbitration replicas in the `sys` tenant. If an empty set is returned, the arbitration service is available in the current tenant.

   ```shell
   obclient [oceanbase]> (SELECT distinct ls_id FROM GV$OB_LOG_STAT WHERE tenant_id = 1) except
   (SELECT ls_id FROM GV$OB_LOG_STAT WHERE tenant_id = 1 and role = 'LEADER' and arbitration_member = "10.10.10.3:2882");
   Empty set
   ```

## What to do next

After the cluster is created, you can create user tenants based on your business needs.

For more information about how to create a tenant by using the CLI, see [Create a tenant](../../../../600.manage/200.tenant-management/600.common-tenant-operations/200.manage-create-tenant.md).

## References

* [Connect to an OceanBase tenant by using OBClient](../../../../300.develop/100.application-development-of-mysql-mode/100.connect-to-oceanbase-database-of-mysql-mode/300.connect-to-an-oceanbase-tenant-by-using-obclient-of-mysql-mode.md)
* [System parameters](../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/200.system-configuration-items-overview-list.md)
* [ALTER USER](../../../../700.reference/500.sql-reference/100.sql-syntax/200.common-tenant-of-mysql-mode/600.sql-statement-of-mysql-mode/1800.alter-user-of-mysql-mode.md)
* [ALTER TENANT](../../../../700.reference/500.sql-reference/100.sql-syntax/100.system-tenants/500.alter-tenant.md)
* [User tenants](../../../../600.manage/200.tenant-management/400.introduction-of-user-tenant.md)
* [CREATE TENANT](../../../../700.reference/500.sql-reference/100.sql-syntax/100.system-tenants/800.create-tenant.md)
* [Enable the arbitration service](../../../../600.manage/400.high-availability/400.arbitration-high-availability/200.enable-the-arbitration-service.md)
* [Disable the arbitration service](../../../../600.manage/400.high-availability/400.arbitration-high-availability/300.disable-the-arbitration-service.md)
* [Modify the downgrade timeout period](../../../../600.manage/400.high-availability/400.arbitration-high-availability/400.modify-the-degradation-timeout.md)
* [Replace the arbitration service](../../../../600.manage/400.high-availability/400.arbitration-high-availability/500.replace-the-arbitration-service.md)
* [Remove the arbitration service](../../../../600.manage/400.high-availability/400.arbitration-high-availability/600.remove-the-arbitration-service.md)