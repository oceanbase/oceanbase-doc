|description||
|---|---|
|keywords||
|dir-name||
|dir-name-en||
|tenant-type|Oracle Mode|

# Configure cgroups

In the current version of OceanBase Database, worker threads and most background threads are identified by tenant, and network threads are shared. You can configure control groups (cgroups) to control the CPU usage of tenants.

## Background information

Before you configure cgroups, we recommend that you learn about the concept of cgroup first. For more information, see [Overview](../100.resource-isolation-overview.md).

## Precautions and limitations

* Resource isolation considerably compromises performance. We recommend that you do not use the cgroup feature to isolate tenant resources in the following scenarios:

   * Single-tenant scenarios that have only one tenant in the cluster.

   * Scenarios where tenants are associated with each other. For example, multiple tenants serve different microservices, resulting in an upstream and downstream relationship among the tenants.

   * Small-scale tenant scenarios where each tenant has two or four CPU cores.

* If the operating system of the OBServer node is Alibaba Cloud Linux, to use the cgroup feature, the operating system version must be 4.1.9 or later.

* The cgroup feature compromises performance of OceanBase Database. Therefore, weigh the isolation benefits and performance loss before you enable the cgroup feature.

## Procedure

### Step 1: Configure the cgroup system directory

<main id="notice" type='notice'>
<h4>Notice</h4>
<ul>
<li>You must configure the cgroup system directory before you install OceanBase Database. </li>
<li>You must obtain the <code>root</code> user privileges when you configure the cgroup system directory. </li>
</ul>
</main>

This topic describes how to configure the cgroup system directory on one OBServer node. If the OceanBase cluster consists of multiple OBServer nodes, you must configure the cgroup system directory on each OBServer node.

1. Log on as the `admin` user to the OBServer server.

2. Run the following command to mount the `/sys/fs/cgroup` directory.

   <main id="notice" type='explain'>
   <h4>Note</h4>
   <p>If the <code>/sys/fs/cgroup</code> directory already exists, skip this step. </p>
   </main>

   ```shell
   [admin@xxx /]$ sudo mount -t tmpfs cgroups /sys/fs/cgroup
   ```

   Here, `cgroups` is a user-defined name for identification when you view the mount information.

   The mounting result is as follows:

   ```shell
   $df
   Filesystem      1K-blocks       Used Available Use% Mounted on
   /               293601280   28055472 265545808  10% /
   /dev/v01d      2348810240 2113955876 234854364  91% /data/1
   /dev/v02d      1300234240 1170211208 130023032  91% /data/log1
   shm              33554432          0  33554432   0% /dev/shm
   /dev/v04d       293601280   28055472 265545808  10% /home/admin/logs
   cgroups         395752136          0 395752136   0% /sys/fs/cgroup
   ```

3. Create a directory named `/sys/fs/cgroup/cpu` and change its owner. This directory is used for mounting the cpu subsystem later.

   ```shell
   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu

   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/blkio
   ```

   <main id="notice" type='explain'>
   <h4>Note</h4>
   <p>If the <code>/sys/fs/cgroup/cpu</code> directory already exists and is empty, skip this step.
   </p>
   </main>

4. Mount the cpu subsystem.

   Create a directory hierarchy named `cpu`, attach the cpu subsystem to this hierarchy, and mount this hierarchy to the `/sys/fs/cgroup/cpu` directory.

   ```shell
   [admin@xxx /]$ sudo mount -t cgroup -o cpu cpu /sys/fs/cgroup/cpu
   ```

5. Create a subdirectory named `oceanbase` and change its owner to `admin`.

   ```shell
   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu/oceanbase

   [admin@xxx /]$ sudo chown admin:admin -R /sys/fs/cgroup/cpu/oceanbase
   ```

6. Run the following commands to set the `oceanbase` directory to inherit the CPU and memory configurations from the upper-level directory and set the lower-level directories of the `oceanbase` directory to automatically inherit its configurations.

   <main id="notice" type='notice'>
   <h4>Notice</h4>
   <p>At present, the cpu, cpuset, and cpuacct subsystems cannot be mounted to different directories. If they are mounted to different directories on your server, clear the mounting information and then run the <code>sudo mount -t cgroup -o cpuset,cpu,cpuacct cpu /sys/fs/cgroup/cpu</code> command to mount them to the same directory. </p>
   </main>

   Confirm that the cpu, cpuset, and cpuacct subsystems are mounted to the same directory and then run the following commands:

   ```shell
   [admin@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.cpus` > /sys/fs/cgroup/cpu/oceanbase/cpuset.cpus"

   [admin@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.mems` > /sys/fs/cgroup/cpu/oceanbase/cpuset.mems"

   [admin@xxx /]$ sudo sh -c "echo 1 > /sys/fs/cgroup/cpu/oceanbase/cgroup.clone_children"
   ```

### Step 2: Deploy OceanBase Database

After the cgroup system directory is configured, you can deploy OceanBase Database. For the deployment procedure, see [Deploy OceanBase Database](../../../../../400.deploy/300.deploy-oceanbase-enterprise-edition/400.deploy-through-the-command-line/200.deploy-the-oceanbase-cluster-command-line/100.stand-alone-deployment-of-oceanbase-database.md).

### Step 3: Establish a soft link to OceanBase Database

After OceanBase Database is installed, establish a soft link between the installation directory of OceanBase Database and the cgroup system directory.

1. Log on as the `admin` user to the OBServer node.

2. Manually establish a soft link between the installation directory of OceanBase Database and the cgroup system directory.

   ```shell
   [admin@xxx /home/admin]$ cd /home/admin/oceanbase/

   [admin@xxx /home/admin]
   $ ln -sf /sys/fs/cgroup/cpu/oceanbase/ cgroup

   [admin@xxx /home/admin]
   $ ln -sf /sys/fs/cgroup/blkio/oceanbase/ cgroup
   ```

   Here, `/home/admin/oceanbase/` is the installation directory of OceanBase Database.

   The execution result is as follows:

   ```shell
   [admin@xxx /home/admin/oceanbase]
   $ll cgroup
   lrwxrwxrwx 1 admin admin 29 Dec  8 11:09 cgroup -> /sys/fs/cgroup/cpu/oceanbase/
   lrwxrwxrwx 1 admin admin 29 Dec  8 11:09 cgroup -> /sys/fs/cgroup/blkio/oceanbase/
   ```

3. Restart the observer process.

   You must first stop the observer process and then restart it. For more information, see [Restart a node](../../../../100.cluster-management/300.common-cluster-operations/300.restart-a-node.md).

   If the observer process detects that a soft link has been established, it will create the cgroup directory in the `/sys/fs/cgroup/cpu/oceanbase/` directory.

   After the observer process is restarted, you can view the cgroup directory structure in the installation directory `/home/admin/oceanbase` of OceanBase Database.

### Step 4: Enable the cgroup feature

In OceanBase Database, the cluster-level `enable_cgroup` parameter specifies whether to enable the cgroup feature for the OBServer node. The default value is `True`, which specifies to enable this feature. If this feature is disabled, perform the following steps to enable it.

1. Log on to the `sys` tenant of the cluster as the `root` user.

2. Execute the following statement to enable the cgroup feature:

   ```shell
   obclient> ALTER SYSTEM SET enable_cgroup = true;
   ```

   or

   ```shell
   obclient> ALTER SYSTEM SET enable_cgroup = 1;
   ```

   or

   ```shell
   obclient> ALTER SYSTEM SET enable_cgroup = ON;
   ```

## What to do next

After you configure the cgroup system directory and enable the cgroup feature, in the case of emergencies, you can control the utilization of CPU resources in a tenant by using the `cpu.cfs_period_us`, `cpu.cfs_quota_us`, and `cpu.shares` files in the directory of the tenant. Generally, we recommend that you do not implement resource isolation in this way.

We recommend that you use the files in the cgroup system directory to call the `CREATE_CONSUMER_GROUP` subprogram in the `DBMS_RESOURCE_MANAGER` package to create resource groups for user-level or SQL statement-level resource isolation. For more information, see [Configure resource isolation within a tenant](200.resource-isolation-at-user-level-of-oracle-mode.md).

## References

[Clear cgroup configurations](../200.resource-isolation-of-oracle-mode/800.clear-cgroup-configuration-of-oracle-mode.md)