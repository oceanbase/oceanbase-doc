|description||
|---|---|
|keywords||
|dir-name||
|dir-name-en||
|tenant-type|MySQL Mode|

# Configure cgroups

This topic describes how to configure cgroups in OceanBase Database.

## Background information

In the current version of OceanBase Database, worker threads and most background threads are distinguished based on the tenant, and network threads are shared threads. Therefore, you can control the CPU usage of the tenant through cgroup configuration. Before you configure cgroups, we recommend that you learn about the concept of cgroup first. For more information, see [Overview](../100.resource-isolation-overview.md).

## Precautions and limitations

* Resource isolation considerably compromises performance. We recommend that you do not use the cgroup feature to isolate tenant resources in the following scenarios:

   * Single-tenant scenarios that have only one tenant in the cluster.

   * Scenarios where tenants are associated with each other. For example, multiple tenants serve different microservices, resulting in an upstream and downstream relationship among the tenants.

   * Small-scale tenant scenarios where each tenant has two or four CPU cores.

* If the operating system of the OBServer node is Alibaba Cloud Linux, to use the cgroup feature, the operating system version must be 4.1.9 or later.

* The cgroup feature compromises performance of OceanBase Database. Therefore, weigh the isolation benefits and performance loss before you enable the cgroup feature.

## Procedure (OceanBase Database Enterprise Edition)

### Step 1: Configure the cgroup system directory

<main id="notice" type='notice'>
<h4>Notice</h4>
<ul>
<li>You must configure the cgroup system directory before you install OceanBase Database. </li>
<li>You must obtain the <code>root</code> user privileges when you configure the cgroup system directory. </li>
</ul>
</main>

This topic describes how to configure the cgroup system directory on one OBServer node. If the OceanBase cluster consists of multiple OBServer nodes, you must configure the cgroup system directory on each OBServer node.

1. Log on as the `admin` user to the OBServer server.

2. Run the following command to mount the `/sys/fs/cgroup` directory.

   <main id="notice" type='explain'>
   <h4>Note</h4>
   <p>If the <code>/sys/fs/cgroup</code> directory already exists, skip this step. </p>
   </main>

   ```shell
   [admin@xxx /]$ sudo mount -t tmpfs cgroups /sys/fs/cgroup
   ```

   Here, `cgroups` is a user-defined name for identification when you view the mount information.

   The mounting result is as follows:

   ```shell
   $df
   Filesystem      1K-blocks       Used Available Use% Mounted on
   /               293601280   28055472 265545808  10% /
   /dev/v01d      2348810240 2113955876 234854364  91% /data/1
   /dev/v02d      1300234240 1170211208 130023032  91% /data/log1
   shm              33554432          0  33554432   0% /dev/shm
   /dev/v04d       293601280   28055472 265545808  10% /home/admin/logs
   cgroups         395752136          0 395752136   0% /sys/fs/cgroup
   ```

3. Create a directory named `/sys/fs/cgroup/cpu` and change its owner. This directory is used for mounting the cpu subsystem later.

   ```shell
   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu

   [admin@xxx /]$ sudo chown admin:admin -R /sys/fs/cgroup/cpu
   ```

   <main id="notice" type='explain'>
   <h4>Note</h4>
   <p>If the <code>/sys/fs/cgroup/cpu</code> directory already exists and is empty, skip this step.
   </p>
   </main>

4. Mount the cpu subsystem.

   Create a directory hierarchy named `cpu`, attach the cpu subsystem to this hierarchy, and mount this hierarchy to the `/sys/fs/cgroup/cpu` directory.

   ```shell
   [admin@xxx /]$ sudo mount -t cgroup -o cpu cpu /sys/fs/cgroup/cpu
   ```

5. Create a subdirectory named `oceanbase` and change its owner to `admin`.

   ```shell
   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu/oceanbase

   [admin@xxx /]$ sudo chown admin:admin -R /sys/fs/cgroup/cpu/oceanbase
   ```

6. Run the following commands to set the `oceanbase` directory to inherit the CPU and memory configurations from the upper-level directory and set the lower-level directories of the `oceanbase` directory to automatically inherit its configurations.

   <main id="notice" type='notice'>
   <h4>Notice</h4>
   <p>At present, the cpu, cpuset, and cpuacct subsystems cannot be mounted to different directories. If they are mounted to different directories on your server, clear the mounting information and then run the <code>sudo mount -t cgroup -o cpuset,cpu,cpuacct cpu /sys/fs/cgroup/cpu</code> command to mount them to the same directory. </p>
   </main>

   Confirm that the cpu, cpuset, and cpuacct subsystems are mounted to the same directory and then run the following commands:

   ```shell
   [admin@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.cpus` > /sys/fs/cgroup/cpu/oceanbase/cpuset.cpus"

   [admin@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.mems` > /sys/fs/cgroup/cpu/oceanbase/cpuset.mems"

   [admin@xxx /]$ sudo sh -c "echo 1 > /sys/fs/cgroup/cpu/oceanbase/cgroup.clone_children"
   ```

### Step 2: Deploy OceanBase Database

After the cgroup system directory is configured, you can deploy OceanBase Database Enterprise Edition. For the deployment procedure, see [Deploy OceanBase Database](../../../../../400.deploy/300.deploy-oceanbase-enterprise-edition/400.deploy-through-the-command-line/200.deploy-the-oceanbase-cluster-command-line/100.stand-alone-deployment-of-oceanbase-database.md).

### Step 3: Establish a soft link to OceanBase Database

After OceanBase Database is installed, establish a soft link between the installation directory of OceanBase Database and the cgroup system directory.

1. Log on as the `admin` user to the OBServer node.

2. Manually establish a soft link between the installation directory of OceanBase Database and the cgroup system directory.

   ```shell
   [admin@xxx /home/admin]$ cd /home/admin/oceanbase/

   [admin@xxx /home/admin]
   $ ln -sf /sys/fs/cgroup/cpu/oceanbase/ cgroup
   ```

   `/home/admin/oceanbase/` is the installation directory of OceanBase Database.

   The execution result is as follows:

   ```shell
   [admin@xxx /home/admin/oceanbase]
   $ll cgroup
   lrwxrwxrwx 1 admin admin 29 Dec  8 11:09 cgroup -> /sys/fs/cgroup/cpu/oceanbase/
   ```

3. Restart the observer process.

   You must first stop the observer process and then restart it. For more information, see [Restart a node](../../../../100.cluster-management/300.common-cluster-operations/300.restart-a-node.md).

   If the observer process detects that a soft link has been established, it will create the cgroup directory in the `/sys/fs/cgroup/cpu/oceanbase/` directory.

4. Log on to the `sys` tenant of the cluster and query the view `V$OB_CGROUP_CONFIG` or `GV$OB_CGROUP_CONFIG` to view the cgroup configuration for each OBServer node.

   ```sql
   SELECT * FROM oceanbase.GV$OB_CGROUP_CONFIG;
   ```

### Step 4: Enable the cgroup feature

In OceanBase Database, the cluster-level `enable_cgroup` parameter specifies whether to enable the cgroup feature for the OBServer node. The default value is `True`, which specifies to enable this feature. If this feature is disabled, perform the following steps to enable it.

1. Log on to the `sys` tenant of the cluster as the `root` user.

2. Execute the following statement to enable the cgroup feature:

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=true;
   ```

   or

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=1;
   ```

   or

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=ON;
   ```

## Procedure (OceanBase Database Community Edition)

### Step 1: Configure the cgroup system directory

<main id="notice" type='notice'>
<h4>Notice</h4>
<ul>
<li>The configuration of the cgroup system directory needs to be performed before installing OceanBase Database.</li>
<li>Configuring the cgroup system directory requires <code>root</code> user privileges.
</li>
</ul>
</main>

This section describes how to configure the cgroup system directory on one OBServer node as the `usercg` user. If the OceanBase cluster consists of multiple OBServer nodes, you must configure the cgroup system directory on each OBServer node.

1. Log on as the `usercg` user to the OBServer server.

2. Run the following command to mount the `/sys/fs/cgroup` directory.

   <main id="notice" type='explain'>
   <h4>Note</h4>
   <p>If the <code>/sys/fs/cgroup</code> directory already exists, skip this step. </p>
   </main>

   ```shell
   [usercg@xxx /]$ sudo mount -t tmpfs cgroups /sys/fs/cgroup
   ```

   Here, `cgroups` is a user-defined name for identification when you view the mount information.

   The mounting result is as follows:

   ```shell
   $df
   Filesystem      1K-blocks       Used Available Use% Mounted on
   /               293601280   28055472 265545808  10% /
   /dev/v01d      2348810240 2113955876 234854364  91% /data/1
   /dev/v02d      1300234240 1170211208 130023032  91% /data/log1
   shm              33554432          0  33554432   0% /dev/shm
   /dev/v04d       293601280   28055472 265545808  10% /home/usercg/logs
   cgroups         395752136          0 395752136   0% /sys/fs/cgroup
   ```

3. Create a directory named `/sys/fs/cgroup/cpu` and change its owner. This directory is used for mounting the cpu subsystem later.

   ```shell
   [usercg@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu

   [usercg@xxx /]$ sudo chown usercg:users -R /sys/fs/cgroup/cpu
   ```

   <main id="notice" type='explain'>
    <h4>Note</h4>
    <p>If the <code>/sys/fs/cgroup/cpu</code> directory already exists and is empty, skip this step.
    </p>
   </main>

4. Mount the cpu subsystem.

   Create a directory hierarchy named `cpu`, attach the cpu subsystem to this hierarchy, and mount this hierarchy to the `/sys/fs/cgroup/cpu` directory.

   ```shell
   [usercg@xxx /]$ sudo mount -t cgroup -o cpu cpu /sys/fs/cgroup/cpu
   ```
  
5. Create a subdirectory named `oceanbase` and change its owner to `usercg`.

   ```shell
   [usercg@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu/oceanbase

   [usercg@xxx /]$ sudo chown usercg:users -R /sys/fs/cgroup/cpu/oceanbase
   ```

6. Run the following commands to set the `oceanbase` directory to inherit the CPU and memory configurations from the upper-level directory and set the lower-level directories of the `oceanbase` directory to automatically inherit its configurations.

   <main id="notice" type='notice'>
   <h4>Notice</h4>
   <p>At present, the cpu, cpuset, and cpuacct subsystems cannot be mounted to different directories. If they are mounted to different directories on your server, clear the mounting information and then run the <code>sudo mount -t cgroup -o cpuset,cpu,cpuacct cpu /sys/fs/cgroup/cpu</code> command to mount them to the same directory. </p>
   </main>

   Confirm that the cpu, cpuset, and cpuacct subsystems are mounted to the same directory and then run the following commands:

   ```shell
   [usercg@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.cpus` > /sys/fs/cgroup/cpu/oceanbase/cpuset.cpus"

   [usercg@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.mems` > /sys/fs/cgroup/cpu/oceanbase/cpuset.mems"

   [usercg@xxx /]$ sudo sh -c "echo 1 > /sys/fs/cgroup/cpu/oceanbase/cgroup.clone_children"
   ```

### Step 2: Deploy OceanBase Database

After the cgroup system directory is configured, you can deploy OceanBase Database Community Edition. For more information about how to deploy OceanBase Database Community Edition, see [Deploy OceanBase Database on CLI in a production environment](../../../../../400.deploy/500.deploy-oceanbase-database-community-edition/200.local-deployment/500.deploy-OceanBase-database-of-multi-node-cluster.md).

<main id="notice" type='explain'>
  <h4>Note</h4>
  <p>Only OceanBase Database Community Edition V4.0.0 and later support the complete cgroup feature. </p>
</main>

### Step 3: Establish a soft link to OceanBase Database

After OceanBase Database is installed, establish a soft link between the installation directory of OceanBase Database and the cgroup system directory.

1. Log on to the OBServer node as the `usercg` user.

2. Manually establish a soft link between the installation directory of OceanBase Database and the cgroup system directory.

   ```shell
   [usercg@xxx /home/usercg]$ cd /home/usercg/oceanbase/

   [usercg@xxx /home/usercg]
   $ ln -sf /sys/fs/cgroup/cpu/oceanbase/ cgroup
   ```

   Here, `/home/usercg/oceanbase/` is the installation path of OceanBase Database.

   The execution result is as follows:

   ```shell
   [usercg@xxx /home/usercg/oceanbase]
   $ll cgroup
   lrwxrwxrwx 1 usercg usercg 29 Dec  8 11:09 cgroup -> /sys/fs/cgroup/cpu/oceanbase/
   ```

3. Restart the observer process.

   You must first stop the observer process and then restart it. For more information, see [Restart a node](../../../../100.cluster-management/300.common-cluster-operations/300.restart-a-node.md).

   If the observer process detects that a soft link has been established, it will create the cgroup directory in the `/sys/fs/cgroup/cpu/oceanbase/` directory.


4. Log on to the `sys` tenant of the cluster and query the view `V$OB_CGROUP_CONFIG` or `GV$OB_CGROUP_CONFIG` to view the cgroup configurations on each OBServer node.

   ```sql
   SELECT * FROM oceanbase.GV$OB_CGROUP_CONFIG;
   ```

### Step 4: Enable the cgroup feature

In OceanBase Database, the cluster-level `enable_cgroup` parameter specifies whether to enable the cgroup feature for the OBServer node. The default value is `True`, which specifies to enable this feature. If this feature is disabled, perform the following steps to enable it.

1. Log on to the `sys` tenant of the cluster as the `root` user.

2. Run the following command to enable the cgroup feature:

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=true;
   ```

   or

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=1;
   ```

   or

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=ON;
   ```

## What to do next

After you configure the cgroup system directory and enable the cgroup feature, in the case of emergencies, you can control the utilization of CPU resources in a tenant by using the `cpu.cfs_period_us`, `cpu.cfs_quota_us`, and `cpu.shares` files in the directory of the tenant. Generally, we recommend that you do not implement resource isolation in this way.

We recommend that you use the files in the cgroup system directory to call the `CREATE_CONSUMER_GROUP` subprogram in the `DBMS_RESOURCE_MANAGER` package to create resource groups for user-level or SQL statement-level resource isolation. For more information about user-level and SQL statement-level resource isolation, see the following topics:

* [Configure user-level resource isolation](../300.resource-isolation-of-mysql-mode/200.resource-isolation-at-user-level-of-mysql-mode.md)

* [Configure SQL statement-level resource isolation](../300.resource-isolation-of-mysql-mode/300.resource-isolation-at-sql-level-of-mysql-mode.md)

## References

[Clear cgroup configurations](../300.resource-isolation-of-mysql-mode/800.clear-cgroup-configuration-of-mysql-mode.md)
