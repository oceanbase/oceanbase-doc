# 在 Kubernetes 环境中部署 OceanBase 数据库

本文介绍如何通过 ob-operator 在 Kubernetes 环境中部署 OceanBase 数据库。目前仅测试了 Kubernetes 1.23.6 版本，其他版本中部署如果有问题，欢迎和我们联系。

本文主要分为以下三部分：

1. 部署 ob-operator

2. 部署 OceanBase 数据库

3. 监控 OceanBase 数据库

## 部署 ob-operator

使用 ob-operator 可以简化 OceanBase 数据库在 Kubernetes 中的部署和运维，您可通过以下两种方式部署 ob-operator。

### 使用 Helm 部署

您可执行以下命令部署 ob-operator。

```shell
helm repo add ob-operator https://oceanbase.github.io/ob-operator/
helm install ob-operator ob-operator/ob-operator --namespace=oceanbase-system --create-namespace  --version=1.2.0
```

### 使用配置文件部署

您可执行如下命令使用配置文件部署 ob-operator。

```shell
# deploy CRD
kubectl apply -f https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/crd.yaml

# deploy ob-operator
kubectl apply -f https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/operator.yaml
```

#### ob-operator 自定义

如果您需要对 ob-operator 进行自定义修改，可执行如下命令下载配置文件。

```shell
# download the config file
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/crd.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/operator.yaml
```

根据自身需求修改配置文件后，执行如下命令进行自定义部署。

```shell
# after making some modification
kubectl apply -f crd.yaml
kubectl apply -f operator.yaml
```

## 部署 OceanBase 数据库

### 部署前准备

#### 配置 Kubernetes 节点 label

ob-operator 会根据 OceanBase 数据库配置文件 `obcluster.yaml` 中的 `nodeSelector` 来决定 observer 节点的分布，因此需要首先对 Kubernetes 的 node 节点配置 label。

您可以通过如下命令来设置 node 的 label。

```shell
kubectl label node <node_name> <label_key>=<label_value>

# for example
kubectl label node node1 ob.zone=zone1
```

#### 部署 local-path-provisioner

ob-operator 在部署 OceanBase 数据库时需要创建 PVC 作为 OceanBase 数据库的存储，出于性能考虑，推荐使用本地存储。本文中使用 local-path-provisioner 来管理 PVC。

部署命令如下：

```shell
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.24/deploy/local-path-storage.yaml
```

更多信息可以参考 [local-path-provisioner](https://github.com/rancher/local-path-provisioner)。

### 部署 OceanBase 数据库

OceanBase 数据库集群通过 yaml 配置文件进行定义，您可参考 ob-operator 提供的配置文件进行自定义的修改，通过如下命令下载 OceanBase 数据库的配置文件 `obcluster.yaml`。

```shell
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/obcluster.yaml
```

配置文件内容示例如下。

```yaml
apiVersion: cloud.oceanbase.com/v1
kind: OBCluster
metadata:
  name: ob-test
  namespace: obcluster
spec:
  imageRepo: oceanbase/oceanbase-ce
  tag: 4.0.0.0-100000272022110114
  imageObagent: oceanbase/obagent:1.2.0
  clusterID: 1
  topology:
    - cluster: cn
      zone:
      - name: zone1
        region: region1
        nodeSelector:
          ob.zone: zone1
        replicas: 1
      - name: zone2
        region: region1
        nodeSelector:
          ob.zone: zone2
        replicas: 1
      - name: zone3
        region: region1
        nodeSelector:
          ob.zone: zone3
        replicas: 1
      parameters:
        - name: log_disk_size
          value: "40G"
  resources:
    cpu: 2
    memory: 10Gi
    storage:
      - name: data-file
        storageClassName: "local-path"
        size: 50Gi
      - name: data-log
        storageClassName: "local-path"
        size: 50Gi
      - name: log
        storageClassName: "local-path"
        size: 30Gi
      - name: obagent-conf-file
        storageClassName: "local-path"
        size: 1Gi
    volume:
        name: backup
        nfs:
          server: ${nfs_server_address}
          path: /opt/nfs
          readOnly: false
```

主要配置介绍如下。

- `imageRepo`：OceanBase 镜像 repo。

- `tag`：OceanBase 镜像 tag。

- `imageObagent`: OBAgent 的镜像，用来做 OceanBase 集群的监控数据采集。
  
- `cluster`：按需配置，如果需要在该 Kubernetes 中部署 OceanBase 集群，请将 cluster 配置为与 ob-operator 启动参数 `--cluster-name` 相同（默认值为 `cn`）。

- `nodeSelector`: 当前 Zone 的 node 选择策略，按照 node 的 label 进行匹配。该配置即上文部署前准备中配置 Kubernetes 节点 label 所用配置。

- `parameters`：按需配置，自定义的 OceanBase 数据库配置项。
  
- `cpu`：Pod 的 CPU 资源，建议配置为大于 2 的整数，小于 2 会引发系统异常。
  
- `memory`：Pod 的 Memory 资源，建议配置值大于 10 Gi，小于 10 Gi 会引发系统异常。
  
- `data-file`：OceanBase 数据存储配置，可以指定大小和 `storageClassName`，用作 OceanBase 的数据目录，建议至少配置为 `memory` 大小的 3 倍以上。
  
- `data-log`：OceanBase 日志存储配置，可以指定大小和 `storageClassName`，用作 OceanBase 的 Clog 目录，建议大小至少配置为 `memory` 大小的 3 倍以上。

- `log`：OceanBase 进程日志存储配置，可以指定大小和 `storageClassName`，用作 OceanBase 进程日志的存放目录，建议大小至少配置为 10Gi 以上。

- `obagent-conf-file`：OBAgent 配置文件目录存储配置，用来存放 OBAgent 配置文件，不需要配置特别大，一般配置大小为 1Gi 就可以。

- `volume`: 用作备份数据的存储，无备份需求可以不配置，但是集群创建成功之后无法再另外添加，需提前做好规划。

配置文件修改之后可以通过如下命令进行部署：

```shell
kubectl apply -f obcluster.yaml
```

### 部署 ODP

ODP 通过 yaml 配置文件进行定义，您可参考 ob-operator 提供的配置文件进行自定义的修改，通过如下命令下载 ODP 的配置文件：

```shell
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/obproxy/deployment.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/obproxy/service.yaml
```

deployment.yaml 文件内容如下：

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: obproxy
  namespace: obcluster
spec:
  selector:
    matchLabels:
      app: obproxy
  replicas: 2
  template:
    metadata:
      labels:
        app: obproxy
    spec:
      containers:
        - name: obproxy
          image: oceanbase/obproxy-ce:4.0.0-5
          ports:
            - containerPort: 2883
              name: "sql"
            - containerPort: 2884
              name: "prometheus"
          env:
            - name: APP_NAME
              value: helloworld
            - name: OB_CLUSTER
              value: ob-test
            - name: RS_LIST
              value: $RS_LIST
          resources:
            limits:
              memory: 2Gi
              cpu: "1"
```

主要环境变量配置说明：

- APP_NAME：ODP 的应用名称。

- OB_CLUSTER：ODP 连接的 OceanBase 集群名。

- RS_LIST：OceanBase 集群的 rs_list，格式为 `${ip1}:${port1};${ip2}:${port2};${ip3}:${port3}`，需要根据实际部署情况来进行替换。rs_list 的地址可以通过以下两种方法获取。

  - 方法一：连接到 OceanBase 集群中执行 `show parameters like 'rootservice_list';` 命令查看。

  - 方法二：通过 `kubectl get RootService rs-${cluster_name} -n ${namespace} -o yaml` 命令查询出所有 Root Service 地址之后拼接成完整的 rs_list， 其中 `${cluster_name}` 和 `${namespace}` 需要替换成部署的 OceanBase 集群名和 namespace。

service.yaml 文件中会开放两个端口，一个用来作 SQL 连接的端口，一个是监控数据的采集端口。service.yaml 文件内容如下：

```yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: obproxy-service
  namespace: obcluster
spec:
  type: NodePort
  selector:
    app: obproxy
  ports:
    - name: "sql"
      port: 2883
      targetPort: 2883
      nodePort: 30083
    - name: "prometheus"
      port: 2884
      targetPort: 2884
      nodePort: 30084
```

配置文件修改后可通过以下命令进行部署：

```shell
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
```

### 连接 OceanBase 集群

推荐通过 ODP 来连接 OceanBase，在部署好 OceanBase 数据库和 ODP 后，您可通过以下命令来获取 ODP 的 service 连接地址。

```shell
kubectl get svc ${servicename} -n ${namespace}

# for example
kubectl get svc obproxy-service -n obcluster

# output
NAME              TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE
obproxy-service   NodePort   xxx.xxx.xxx.xxx   <none>        2883:30083/TCP,2884:30084/TCP   1m
```

您可以通过 CLUSTER-IP 和 PORT 的方式进行连接，对应的连接命令如下。

```shell
# use clusterip without password
obclient -hxxx.xxx.xxx.xxx -P2883 -uroot@sys oceanbase -A -c

# use clusterip with password
obclient -hxxx.xxx.xxx.xxx -P2883 -uroot@sys -p oceanbase -A -c

# using nodeport without password
obclient -h<node_ip> -P30083 -uroot@sys oceanbase -A -c

# using nodeport with password
obclient -h<node_ip> -P30083 -uroot@sys -p oceanbase -A -c
```

## 监控 OceanBase 数据库

### 部署 Prometheus

您可参考 ob-operator 提供的 Prometheus 配置文件进行自定义的修改，通过如下命令下载 Prometheus 的配置文件：

```shell
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/prometheus/cluster-role.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/prometheus/cluster-role-binding.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/prometheus/configmap.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/prometheus/deployment.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/prometheus/service.yaml
```

Prometheus 根据 Kubernetes 中服务的名称和端口来选择收集数据的地址，可以按照正则表达式进行过滤，如下所示在 configmap.yaml 中进行配置。

```yaml
# configmap.yaml中部分配置
scrape_configs:
  - job_name: 'obagent-monitor-basic'
    kubernetes_sd_configs:
      - role: endpoints
    metrics_path: '/metrics/ob/basic'
    relabel_configs:
    - source_labels: [__meta_kubernetes_endpoints_name,__meta_kubernetes_endpoint_port_name]
      regex: svc-monitor-ob-test;monagent
      action: keep
  - job_name: 'obagent-monitor-extra'
    kubernetes_sd_configs:
      - role: endpoints
    metrics_path: '/metrics/ob/extra'
    relabel_configs:
    - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_pod_container_port_name]
      regex: svc-monitor-ob-test;monagent
      action: keep
  - job_name: 'obagent-monitor-host'
    kubernetes_sd_configs:
      - role: endpoints
    metrics_path: '/metrics/node/host'
    relabel_configs:
    - source_labels: [__meta_kubernetes_endpoints_name,__meta_kubernetes_endpoint_port_name]
      regex: svc-monitor-ob-test;monagent
      action: keep
  - job_name: 'proxy-monitor'
    kubernetes_sd_configs:
      - role: endpoints
    metrics_path: '/metrics'
    relabel_configs:
    - source_labels: [__meta_kubernetes_endpoints_name,__meta_kubernetes_endpoint_port_name]
      regex: obproxy-service;prometheus
      action: keep
```

配置介绍如下。

- service 和 port 说明:

  - OceanBase: ob-operator 会根据部署的 OceanBase 集群名称创建一个 service 用来获取 exporter 地址，service 命名的规则是 `svc-monitor-${obcluster_name}`，端口名为 `monagent`，如果部署 OceanBase 集群时自定义了集群名，需要根据实际的集群名称来修改对应配置。
  
  - ODP: 需要配置对应 ODP 的 service 和 port name。

- 监控指标的请求路径:

  - OceanBase 集群监控指标：请求路径分别为 `/metrics/ob/basic` 和 `/metrics/ob/extra`。
  
  - ODP 集群监控指标: ODP 自身支持了 prometheus 协议暴露监控指标的能力，请求路径为 `/metrics`。

配置文件修改之后可以通过以下命令进行部署：

```shell
kubectl apply -f cluster-role.yaml
kubectl apply -f cluster-role-binding.yaml
kubectl apply -f configmap.yaml
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
```

#### 验证

浏览器打开 Prometheus 的地址，查看 **Status** -> **Targets**，验证 `proxy-monitor`、`obagent-monitor-host`、`obagent-monitor-basic`、`obagent-monitor-extra` 下的 `Endpoint` 都是 up 状态。

单击 Graph，可以输入 PromQL 表达式进行查询。

### 部署 Grafana

您可参考 ob-operator 提供的 Grafana 配置文件进行自定义的修改，通过如下命令下载 Grafana 的配置文件：

```shell
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/grafana/configmap.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/grafana/pvc.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/grafana/deployment.yaml
wget https://raw.githubusercontent.com/oceanbase/ob-operator/1.2.0_release/deploy/grafana/service.yaml
```

Grafana 通过 configmap.yaml 文件设置关键配置信息，包括 Prometheus 数据源的地址。如果 Prometheus 进行了自定义部署，需要配置实际的 service 地址。

```yaml
# configmap 中关键配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: obcluster
data:
  prometheus.yaml: |-
    {
        "apiVersion": 1,
        "datasources": [
            {
               "access":"proxy",
                "editable": true,
                "name": "prometheus",
                "orgId": 1,
                "type": "prometheus",
                "url": "http://svc-prometheus.obcluster.svc:8080",
                "version": 1,
                "isDefault": true
            }
        ]
    }
```

其中，Grafana 的配置中会使用到 Prometheus 的服务地址作为数据源的配置（`datasources` 中的 `url` 字段），需要根据 Prometheus 的实际部署情况来填写。

配置文件修改之后可以通过以下命令进行部署：

```shell
kubectl apply -f configmap.yaml
kubectl apply -f pvc.yaml
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml
```

#### 验证

浏览器打开 Grafana 的地址，通过 `admin` 用户登陆，默认密码也是 `admin`，第一次登录会提示修改密码。Grafana 的配置中默认携带了 OceanBase 数据库的 dashboard，可以在浏览器中打开以下链接查看：

```shell
http://${node_ip}:${node_port}/d/oceanbase
```

主机指标和 ODP 的监控模版可以通过添加如下 id 对应的 dashboard 进行查看。

- 主机：15216

- ODP：15354

<main id="notice" type='explain'>
  <h4>说明</h4>
  <p>ODP 需要有实际请求之后，才会有监控数据展示</p>
</main>
