# 使用命令行部署单机集中式 OceanBase 数据库

单机集中式是 OceanBase 为用户推出的极简数据库架构，相较于分布式集群，单机集中式仅仅包含一个 Zone 并且 Zone 中只有一个 OBServer 节点。但无多副本及扩缩容能力，适用于开发测试以及数据安全要求不高的业务系统。

本文介绍如何使用命令行部署单机集中式 OceanBase 数据库。

## 注意事项

如果部署的 OceanBase 数据库要实现资源隔离，那么在部署 OceanBase 数据库之前要先配置 cgroup。

有关资源隔离和配置 cgroup 的更多信息，请参见 [资源隔离概述](../../../../600.manage/200.tenant-management/600.common-tenant-operations/300.resource-isolation/100.resource-isolation-overview.md) 和 [配置 cgroup](../../../../600.manage/200.tenant-management/600.common-tenant-operations/300.resource-isolation/200.resource-isolation-of-oracle-mode/100.config-cgroups-of-oracle-mode.md)。

## 前提条件

在安装 OceanBase 数据库之前，需要确认以下信息：

* OBServer 服务器已完成相关配置。详细信息，请参见 [服务器配置](../../200.preparations-before-deploy/200.configure-servers.md) 和 [使用 oatcli 初始化 OBServer 服务器](../100.configure-a-deployment-environment-command-line/100.initializing-the-observer-server-using-oatcli.md)。

* 已获取 OceanBase 数据库 RPM 包。详细信息，请参见 [准备安装包](../../200.preparations-before-deploy/300.prepare-installation-packages.md)。

## 操作步骤

### 步骤一：安装 RPM 包

1. 安装 OceanBase 数据库 RPM 包。

   ```shell
   [root@xxx /]# cd $rpm_dir
   [root@xxx $rpm_dir]# rpm -ivh $rpm_name
   ```

   其中 `$rpm_dir` 表示存放 RPM 包的目录，`$rpm_name` 表示 RPM 包的名称。

   <main id="notice" type='explain'>
      <h4>说明</h4>
      <p>OceanBase 数据库软件会默认安装在目录 <code>/home/admin/oceanbase</code> 下。</p>
   </main>

   示例如下：

   ```shell
   [root@xxx /home/admin/rpm]# rpm -ivh oceanbase-4.2.0.0-100000052023073123.el7.x86_64.rpm
   Preparing...                          ################################# [100%]
   Updating / installing...
      1:oceanbase-4.2.0.0-100000052023073################################# [100%]
   ```

2. （可选）安装 OceanBase 客户端。

   OceanBase 客户端 OBClient 是 OceanBase 数据库专用的命令行客户端工具，通过 OBClient 您可以连接 OceanBase 数据库的 MySQL 租户和 Oracle 租户。如果只连接 OceanBase 数据库的 MySQL 租户，也可以通过 MySQL 客户端（mysql）连接 OceanBase 数据库。

   <main id="notice" type='notice'>
      <h4>注意</h4>
      <p>由于 OBClient V2.2.1 之前的版本依赖于 <code>libobclient</code>，所以需要先安装 <code>libobclient</code>。</br>请联系技术支持获取 OBClient RPM 包；如果您使用 OBClient V2.2.1 之前的版本还需获取 libobclient RPM 包。</p>
   </main>

   示例如下：

   ```shell
   [root@xxx /home/admin/rpm]# rpm -ivh obclient-2.2.1-20221122151945.el7.alios7.x86_64.rpm
   Preparing...                          ################################# [100%]
   Updating / installing...
      1:obclient-2.2.1-20221122151945.el7################################# [100%]

   ##核查是否安装成功##
   [root@xxx /home/admin/rpm]# which obclient
   /usr/bin/obclient
   ```

### 步骤二：配置目录

1. （可选）清理目录。

   新机器第一次部署 OceanBase 数据库时不用清理目录。

   如果是以下情况选择直接清理旧的 OceanBase 目录：

   * 清理之前的 OceanBase 环境。
   * OceanBase 安装部署过程中出现问题导致环境变乱或者产生文件影响下一次安装。

   ```shell
   [root@xxx /home/admin]# rm -rf /data/1/$cluster_name 
   [root@xxx /home/admin]# rm -rf /data/log1/$cluster_name 
   [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/store/$cluster_name 
   [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/log/* /home/admin/oceanbase/etc/*config*
   ```

   其中 `$cluster_name` 为集群名。

   示例如下：

   ```shell
   [root@xxx /home/admin]# rm -rf /data/1/obdemo
   [root@xxx /home/admin]# rm -rf /data/log1/obdemo
   [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/store/obdemo
   [root@xxx /home/admin]# rm -rf /home/admin/oceanbase/log/* /home/admin/oceanbase/etc/*config*
   ```

2. 初始化 OceanBase 目录。

   OceanBase 的数据目录通常建议在独立的磁盘上，然后通过软链接方式链接到软件 Home 目录下面。

   ```shell
   ##切换到admin用户##
   [root@xxx /home/admin]# su - admin

   ##使用admin用户执行以下命令##
   -bash-4.2$ mkdir -p /data/1/$cluster_name/{etc3,sstable,slog} 
   -bash-4.2$ mkdir -p /data/log1/$cluster_name/{clog,etc2} 
   -bash-4.2$ mkdir -p /home/admin/oceanbase/store/$cluster_name
   -bash-4.2$ for t in {etc3,sstable,slog};do ln -s /data/1/$cluster_name/$t /home/admin/oceanbase/store/$cluster_name/$t; done
   -bash-4.2$ for t in {clog,etc2};do ln -s /data/log1/$cluster_name/$t /home/admin/oceanbase/store/$cluster_name/$t; done
   ```

   其中 `$cluster_name` 为集群名。`slog` 和 数据文件必须在同一个磁盘上。

   示例如下：

   ```shell
   [root@xxx /home/admin]# su - admin
   -bash-4.2$ mkdir -p /data/1/obdemo/{etc3,sstable,slog}
   -bash-4.2$ mkdir -p /data/log1/obdemo/{clog,etc2}
   -bash-4.2$ mkdir -p /home/admin/oceanbase/store/obdemo
   -bash-4.2$ for t in {etc3,sstable,slog};do ln -s /data/1/obdemo/$t /home/admin/oceanbase/store/obdemo/$t; done
   -bash-4.2$ for t in {clog,etc2};do ln -s /data/log1/obdemo/$t /home/admin/oceanbase/store/obdemo/$t; done
   ```

   <main id="notice" type='explain'>
      <h4>说明</h4>
      <p><code>obdemo</code> 是以集群名称创建的目录，可自定义，在启动进程时会用到。</p>
   </main>

   **检查结果：**

   ```shell
   -bash-4.2$ cd /home/admin/oceanbase
   -bash-4.2$ tree store/
   store/
   `-- obdemo
      |-- clog -> /data/log1/obdemo/clog
      |-- etc2 -> /data/log1/obdemo/etc2
      |-- etc3 -> /data/1/obdemo/etc3
      |-- slog -> /data/1/obdemo/slog
      `-- sstable -> /data/1/obdemo/sstable

   6 directories, 0 files
   ```

### 步骤三：初始化 OceanBase 数据库

<main id="notice" type='explain'>
   <h4>说明</h4>
   <p>示例 IP 做了脱敏处理，这不是安装需求。在部署时应根据自己机器真实 IP 填写。</p>
</main>

1. 启动 observer 进程。

   必须在 `admin` 用户下启动 observer 进程，启动语句如下：

   ```shell
   cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer {-I $ip | -i $devname} -P $rpc_port -p $sql_port -z $zone_name -d /home/admin/oceanbase/store/$cluster_name -r '$ip:2882:2881' -c $cluster_id -n $cluster_name -o "system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/$cluster_name/etc3;/data/log1/$cluster_name/etc2"
   ```

   **参数解释：**

   |**参数**|               **说明**     |
   |--------|----------------------------|
   | `-I` \| `-i`   | <ul><li>`-I`：指定待启动的节点 IP。在多机部署场景下，不能指定 127.0.0.1 作为目标 IP。建议使用指定 IP（例如：`-I 10.10.10.1`）来启动节点。</li><li>`-i`：指定网卡名，可通过 `ifconfig` 命令查看。</li></ul><main id="notice" type='explain'><h4>说明</h4><p>支持通过同时指定 IP 和网卡名（例如：`-I 10.10.10.1 -i eth0`）来启动节点，但不建议这么用。</p></main>|
   | `-p`   | 指定服务端口号，一般指定为 `2881`。|
   | `-P`   | 指定 RPC 端口号，一般指定为 `2882`。|
   | `-n`   | 指定集群名称。可自定义，不同集群名称不要重复即可。|
   | `-z`   | 指定启动的 observer 进程所属的 Zone。|
   | `-d`   | 指定集群主目录，初始化目录时创建的目录。除集群名字 `$cluster_name` 外，其他不要变动。|
   | `-c`   | 指定集群 ID。为一组数字，可以自定义，不同集群不要重复即可。|
   | `-l`   | 指定日志级别。|
   | `-r`   | 指定 RS 列表，格式是 `$ip:2882:2881`，分号分割，表示 Root Service 信息。|
   | `-o`   | 指定集群启动参数，需要根据实际情况设置。<ul><li>`system_memory`：指定 OceanBase 内部保留内存，默认是 `30G` ，机器内存比较少的情况下把这个调小，影响就是可能在性能测试时有内存不足问题。</li><li>`datafile_size`：指定 OceanBase 数据文件 `sstable` 的大小（一次性初始化），根据 `/data/1/` 可用空间评估，建议不少于 `100G`，同时又保留一些剩余空间。</li><li>`config_additional_dir` 指定参数文件的冗余目录。</li></ul>|

   示例如下：

   ```shell
   [root@xxx /home/admin]# su - admin
   -bash-4.2$ cd /home/admin/oceanbase && /home/admin/oceanbase/bin/observer -I 10.10.10.1 -P 2882 -p 2881 -z zone1 -d /home/admin/oceanbase/store/obdemo -r '10.10.10.1:2882:2881' -c 10001 -n obdemo -o "system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/obdemo/etc3;/data/log1/obdemo/etc2"
   ```

   可以通过下面命令查看 observer 进程是否启动成功：

   * `netstat -ntlp` 命令，如果监听到了 `2881` 与 `2882` 端口，则说明进程启动成功。
   * `ps -ef|grep observer` 命令可以返回 observer 进程信息。

   示例如下：

   ```shell
   -bash-4.2$ netstat -ntlp
   (Not all processes could be identified, non-owned process info
   will not be shown, you would have to be root to see it all.)
   Active Internet connections (only servers)
   Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
   tcp        0      0 0.0.0.0:2881            0.0.0.0:*               LISTEN      11111/observer
   tcp        0      0 0.0.0.0:2882            0.0.0.0:*               LISTEN      11111/observer
   ...        ...    ...                       ...                     ...         ...

   -bash-4.2$ ps -ef|grep observer
   admin    11111      0 43 17:58 ?        00:00:14 /home/admin/oceanbase/bin/observer -I 10.10.10.1 -P 2882 -p 2881 -z zone1 -d /home/admin/oceanbase/store/obdemo -r 10.10.10.1:2882:2881 -c 10001 -n obdemo -o system_memory=30G,datafile_size=500G,config_additional_dir=/data/1/obdemo/etc3;/data/log1/obdemo/etc2
   ```

2. 集群 bootstrap 操作。

   通过 OBClient 客户端连接已启动的 observer 进程，密码为空。

   ```shell
   [root@xxx /home/admin]# obclient -h127.1 -uroot -P2881 -p
   Enter password:

   obclient [(none)]> SET SESSION ob_query_timeout=1000000000;
   Query OK, 0 rows affected

   obclient [(none)]> ALTER SYSTEM BOOTSTRAP ZONE 'zone1' SERVER '10.10.10.1:2882';
   Query OK, 0 rows affected
   ```

   <main id="notice" type='notice'>
      <h4>注意</h4>
      <p>如果这一步失败报错了，其原因很可能是 observer 进程启动参数有不对、OBServer 节点相关目录权限不对、日志目录空间不足一定比例（跟数据目录合用了大目录，空间被数据目录占用了）节点内存资源不足等等。请先排查这些问题点后，然后清理 OceanBase 目录从头开始。</p>
   </main>

3. 验证集群初始化成功。

   进行 bootstrap 后，执行 `SHOW DATABASES;` 命令，能看到数据库列表里有 `oceanbase` 库即可。

   ```shell
   obclient [(none)]> SHOW DATABASES;
   +--------------------+
   | Database           |
   +--------------------+
   | information_schema |
   | LBACSYS            |
   | mysql              |
   | oceanbase          |
   | ORAAUDITOR         |
   | SYS                |
   | test               |
   +--------------------+
   7 rows in set
   ```

4. 修改密码。

   `sys` 租户的 `root` 用户密码默认为空，初始化成功后请修改密码。

   ```shell
   obclient [(none)]> ALTER USER root IDENTIFIED BY '******';
   Query OK, 0 rows affected
   ```

## 后续操作

集群创建成功后，可根据业务需要创建用户租户。

使用命令行创建用户租户的详细信息，请参见 [创建租户](../../../../600.manage/200.tenant-management/600.common-tenant-operations/200.manage-create-tenant.md)。

## 相关文档

* [通过 OBClient 连接 OceanBase 租户](../../../../300.develop/100.application-development-of-mysql-mode/100.connect-to-oceanbase-database-of-mysql-mode/300.connect-to-an-oceanbase-tenant-by-using-obclient-of-mysql-mode.md)
* [系统配置项总览](../../../../700.reference/800.configuration-items-and-system-variables/100.system-configuration-items/200.system-configuration-items-overview-list.md)
* [ALTER USER](../../../../700.reference/500.sql-reference/100.sql-syntax/200.common-tenant-of-mysql-mode/600.sql-statement-of-mysql-mode/1800.alter-user-of-mysql-mode.md)
* [用户租户介绍](../../../../600.manage/200.tenant-management/400.introduction-of-user-tenant.md)
* [CREATE TENANT](../../../../700.reference/500.sql-reference/100.sql-syntax/100.system-tenants/800.create-tenant.md)
* [单机在线转分布式部署](../../../../600.manage/100.cluster-management/300.common-cluster-operations/1400.single-machine-deployment-online-to-distributed.md)
