# 配置 cgroups

本文主要介绍如何为 OceanBase 数据库配置 cgroup。

## 背景信息

OceanBase 数据库的当前版本中，由于租户工作线程和大部分后台线程均根据租户来区分，网络线程为共享线程，用户可以通过配置 cgroup 来控制租户 CPU 的占用。在开始配置 cgroup 前，建议您先了解 cgroup 的概念。有关 cgroup 的介绍信息，参见 [资源隔离概述](../100.resource-isolation-overview.md)。

## 使用限制及注意事项

* 由于设置资源隔离对性能影响比较大，以下场景下不建议使用 cgroup 功能进行租户的资源隔离：

  * 单租户场景，即集群中只有一个租户

  * 租户之间有业务关联的场景，例如，不同的微服务放在不同的租户，从而租户相互间呈上下游关系

  * 小规格租户场景，即 CPU 为 2C 或 4C 的租户

* 使用 cgroup 功能时，如果安装 OceanBase 数据库的操作系统为 Alibaba Cloud Linux，则要求其操作系统版本为 Alibaba Cloud Linux 4.19 及以上版本。

* 开启 cgroup 会导致 OceanBase 数据库的性能有所下降，请权衡隔离性和性能后再确认是否开启。

## 配置 OceanBase 企业版

### 步骤一：配置 cgroup 系统目录

<main id="notice" type='notice'>
<h4>注意</h4>
<p>cgroup 系统目录的配置操作需要在 OceanBase 数据库软件安装前进行。</p>
</main>

本节以在一台 OBServer 上配置 cgroup 系统目录为例，如果有多台 OBServer，则每台 OBServer 上都需要配置。

1. 使用 `admin` 用户登录到 OBServer 服务器所在的机器。

2. 执行以下命令，挂载 `/sys/fs/cgroup` 目录。

   <main id="notice" type='explain'>
   <h4>说明</h4>
   <p>如果已经存在 <code>/sys/fs/cgroup</code> 目录，则可忽略该步骤。</p>
   </main>

   ```shell
   [admin@xxx /]$ sudo mount -t tmpfs cgroups /sys/fs/cgroup
   ```

   其中，`cgroups` 为自定义名称，用于在查看 Mount 信息时进行标识。

   挂载结果如下所示。

   ```shell
   $df
   Filesystem      1K-blocks       Used Available Use% Mounted on
   /               293601280   28055472 265545808  10% /
   /dev/v01d      2348810240 2113955876 234854364  91% /data/1
   /dev/v02d      1300234240 1170211208 130023032  91% /data/log1
   shm              33554432          0  33554432   0% /dev/shm
   /dev/v04d       293601280   28055472 265545808  10% /home/admin/logs
   cgroups         395752136          0 395752136   0% /sys/fs/cgroup
   ```

3. 创建 `/sys/fs/cgroup/cpu` 目录并修改 Owner 后，挂载 CPU 子系统。

   <main id="notice" type='explain'>
   <h4>说明</h4>
   <p>如果已经存在 <code>/sys/fs/cgroup/cpu</code> 目录，则可忽略该步骤。</p>
   </main>

   ```shell
   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu

   [admin@xxx /]$ sudo chown admin:admin -R /sys/fs/cgroup/cpu
   ```

   创建一个名为 `cpu` 的层级，在该层级上附加 cpu 子系统，并且将层级挂载到 `/sys/fs/cgroup/cpu` 目录。

   ```shell
   [admin@xxx /]$ sudo mount -t cgroup -o cpu cpu /sys/fs/cgroup/cpu
   ```
  
4. 创建名为 `oceanbase` 的子目录，并修改其 Owner 为 `admin`。

   ```shell
   [admin@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu/oceanbase

   [admin@xxx /]$ sudo chown admin:admin -R /sys/fs/cgroup/cpu/oceanbase
   ```

5. 为 `oceanbase` 目录分配 CPU 和 Memory 资源。

   1. 执行以下命令，查看机器上 cpu、cpuacct、cpuset 三个子系统的挂载情况。

      ```shell
      [admin@xxx /]$ ll /sys/fs/cgroup
      ```

   2. 根据子系统的挂载情况，选择合适的操作：

      * cpuset 子系统与 cpu、cpuacct 等子系统一起挂载

         该场景下，通常是三个子系统挂载在同一目录下，例如，挂载结果如下所示：

         ```shell
         drwxr-xr-x 3 root root 0 Jul 24 2020 blkio
         lrwxrwxrwx 1 root root 33 Jul 24 2020 cpu -> /sys/fs/cgroup/cpuset,cpu,cpuacct
         lrwxrwxrwx 1 root root 33 Jul 24 2020 cpuacct -> /sys/fs/cgroup/cpuset,cpu,cpuacct
         lrwxrwxrwx 1 root root 33 Jul 24 2020 cpuset -> /sys/fs/cgroup/cpuset,cpu,cpuacct
         drwxr-xr-x 4 root root 0  Jul 24 2020 cpuset,cpu,cpuacct
         ```

         对于该场景，需要执行以下命令来为 `oceanbase` 目录分配 CPU 和 Memory 资源。

         ```shell
         [admin@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.cpus` > /sys/fs/cgroup/cpu/oceanbase/cpuset.cpus"

         [admin@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.mems` > /sys/fs/cgroup/cpu/oceanbase/cpuset.mems"
         ```

      * cpuset 子系统与 cpu、cpuacct 等子系统分开挂载

         该场景下，cpuset 子系统与 cpu、cpuacct 等子系统为分开挂载（通常 ECS 机型较多），其挂载结果如下所示：

         ```shell
         drwxr-xr-x 2 root root 40 2月 27 15:27 blkio
         lrwxrwxrwx 1 root root 11 2月 27 15:27 cpu -> cpu,cpuacct
         lrwxrwxrwx 1 root root 11 2月 27 15:27 cpuacct -> cpu,cpuacct
         drwxr-xr-x 2 root root 40 2月 27 15:27 cpu,cpuacct
         drwxr-xr-x 2 root root 40 2月 27 15:27 cpuset
         ```

         对于该场景，不需要执行额外操作，直接进行下一步即可。

6. 执行以下命令，为 `oceanbase` 目录设置子目录的继承属性。

   ```shell
   [admin@xxx /]$ sudo sh -c "echo 1 > /sys/fs/cgroup/cpu/oceanbase/cgroup.clone_children"
   ```

   命令执行成功后，在 `oceanbase `目录下创建的 cgroup 子目录，其属性均会继承父目录。

### 步骤二：部署数据库

cgroup 系统目录配置成功后，即可部署 OceanBase 数据库。 OceanBase 数据库的详细安装操作请参见 [部署数据库](../../../../../400.deploy/300.deploy-oceanbase-database-enterprise/100.deployment-process.md)。

### 步骤三：与 OceanBase 数据库建立软链接

OceanBase 数据库安装成功后，需要建立 OceanBase 数据库软件的安装目录与 cgroup 系统目录的软链接。

1. 使用 `admin` 用户登录到 OBServer 服务器。

2. 手动建立 OceanBase 数据库软件的安装目录与 cgroup 系统目录的软链接。

   ```shell
   [admin@xxx /home/admin]$ cd /home/admin/oceanbase/

   [admin@xxx /home/admin]
   $ ln -sf /sys/fs/cgroup/cpu/oceanbase/ cgroup
   ```

   其中：`/home/admin/oceanbase/` 为 OceanBase 数据库软件的安装路径。

   执行成功后，结果如下所示。

   ```shell
   [admin@xxx /home/admin/oceanbase]
   $ll cgroup
   lrwxrwxrwx 1 admin admin 29 Dec  8 11:09 cgroup -> /sys/fs/cgroup/cpu/oceanbase/
   ```

3. 重新启动 observer 进程。

   您需要停止 observer 进程后再重新启动 observer 进程，具体操作请参见 [停止或启动 OBServer](../../../200.basic-database-management/100.manage-clusters/500.manage-observer/300.stop-or-start-observer.md)。

   observer 进程在启动时，检测到之前已经建立的软链接，就会在 `/sys/fs/cgroup/cpu/oceanbase/` 目录下继续创建 OceanBase 数据库 cgroup 目录。

   重启成功后，可以在 OceanBase 数据库软件的安装目录 `/home/admin/oceanbase` 下看到 cgroup 的目录结构。

### 步骤四：开启 cgroup 功能

OceanBase 数据库通过集群级配置项 `enable_cgroup` 来控制 OBServer 是否开启 cgroup 功能。默认该功能为 `True`，表示已开启，如果未开启，您可以参考以下操作，开启 cgroup 功能。

1. 使用 `root` 用户登录到集群的 `sys` 租户。

2. 执行以下命令，开启 cgroup 功能。

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=true;
   ```

   或者

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=1;
   ```

   或者

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=ON;
   ```

## 配置 OceanBase 社区版

### 步骤一：配置 cgroup 系统目录

<main id="notice" type='notice'>
<h4>注意</h4>
<ul>
<li>cgroup 系统目录的配置操作需要在 OceanBase 数据库软件安装前进行。</li>
<li>配置 cgroup 系统目录时需要 <code>root</code> 用户权限。</li>
</ul>
</main>

本节以在一台 OBServer 上，用 `usercg` 用户配置 cgroup 系统目录为例，如果有多台 OBServer ，则每台 OBServer 上都需要配置。

1. 使用 `usercg` 用户登录到 OBServer 服务器。

2. 执行以下命令，挂载 `/sys/fs/cgroup` 目录。

   <main id="notice" type='explain'>
   <h4>说明</h4>
   <p>如果已经存在 <code>/sys/fs/cgroup</code> 目录，则可忽略该步骤。</p>
   </main>

   ```shell
   [usercg@xxx /]$ sudo mount -t tmpfs cgroups /sys/fs/cgroup
   ```

   其中，`cgroups` 为自定义名称，用于在查看 Mount 信息时进行标识。

   挂载结果如下所示。

   ```shell
   $df
   Filesystem      1K-blocks       Used Available Use% Mounted on
   /               293601280   28055472 265545808  10% /
   /dev/v01d      2348810240 2113955876 234854364  91% /data/1
   /dev/v02d      1300234240 1170211208 130023032  91% /data/log1
   shm              33554432          0  33554432   0% /dev/shm
   /dev/v04d       293601280   28055472 265545808  10% /home/usercg/logs
   cgroups         395752136          0 395752136   0% /sys/fs/cgroup
   ```

3. 创建 `/sys/fs/cgroup/cpu` 目录并修改 Owner 后，挂载 CPU 子系统。

   <main id="notice" type='explain'>
   <h4>说明</h4>
   <p>如果已经存在 <code>/sys/fs/cgroup/cpu</code> 目录，则可忽略该步骤。</p>
   </main>

   ```shell
   [usercg@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu

   [usercg@xxx /]$ sudo chown usercg:usercg -R /sys/fs/cgroup/cpu
   ```

   创建一个名为 `cpu` 的层级，在该层级上附加 `cpu` 子系统，并且将层级挂载到 `/sys/fs/cgroup/cpu` 目录。

   ```shell
   [usercg@xxx /]$ sudo mount -t cgroup -o cpu cpu /sys/fs/cgroup/cpu
   ```

4. 创建名为 `oceanbase` 的子目录，并修改其 Owner 为 `usercg`。

   ```shell
   [usercg@xxx /]$ sudo mkdir /sys/fs/cgroup/cpu/oceanbase

   [usercg@xxx /]$ sudo chown usercg:usercg -R /sys/fs/cgroup/cpu/oceanbase
   ```

5. 为 `oceanbase` 目录分配 CPU 和 Memory 资源。

   1. 执行以下命令，查看机器上 cpu、cpuacct、cpuset 三个子系统的挂载情况。

      ```shell
      [usercg@xxx /]$ ll /sys/fs/cgroup
      ```

   2. 根据子系统的挂载情况，选择合适的操作：

      * cpuset 子系统与 cpu、cpuacct 等子系统一起挂载

         该场景下，通常是三个子系统挂载在同一目录下，例如，挂载结果如下所示：

         ```shell
         drwxr-xr-x 3 root root 0 Jul 24 2020 blkio
         lrwxrwxrwx 1 root root 33 Jul 24 2020 cpu -> /sys/fs/cgroup/cpuset,cpu,cpuacct
         lrwxrwxrwx 1 root root 33 Jul 24 2020 cpuacct -> /sys/fs/cgroup/cpuset,cpu,cpuacct
         lrwxrwxrwx 1 root root 33 Jul 24 2020 cpuset -> /sys/fs/cgroup/cpuset,cpu,cpuacct
         drwxr-xr-x 4 root root 0  Jul 24 2020 cpuset,cpu,cpuacct
         ```

         对于该场景，需要执行以下命令来为 `oceanbase` 目录分配 CPU 和 Memory 资源。

         ```shell
         [usercg@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.cpus` > /sys/fs/cgroup/cpu/oceanbase/cpuset.cpus"

         [usercg@xxx /]$ sudo sh -c "echo `cat /sys/fs/cgroup/cpu/cpuset.mems` > /sys/fs/cgroup/cpu/oceanbase/cpuset.mems"
         ```

      * cpuset 子系统与 cpu、cpuacct 等子系统分开挂载

         该场景下，cpuset 子系统与 cpu、cpuacct 等子系统为分开挂载（通常 ECS 机型较多），其挂载结果如下所示：

         ```shell
         drwxr-xr-x 2 root root 40 2月 27 15:27 blkio
         lrwxrwxrwx 1 root root 11 2月 27 15:27 cpu -> cpu,cpuacct
         lrwxrwxrwx 1 root root 11 2月 27 15:27 cpuacct -> cpu,cpuacct
         drwxr-xr-x 2 root root 40 2月 27 15:27 cpu,cpuacct
         drwxr-xr-x 2 root root 40 2月 27 15:27 cpuset
         ```

         对于该场景，不需要执行额外操作，直接进行下一步即可。

6. 执行以下命令，为 `oceanbase` 目录设置子目录的继承属性。

   ```shell
   [usercg@xxx /]$ sudo sh -c "echo 1 > /sys/fs/cgroup/cpu/oceanbase/cgroup.clone_children"
   ```

   命令执行成功后，在 `oceanbase `目录下创建的 cgroup 子目录，其属性均会继承父目录。

### 步骤二：部署数据库

cgroup 系统目录配置成功后，即可部署 OceanBase 数据库社区版。 OceanBase 数据库的详细安装操作请参见 [部署 OceanBase 数据库生产环境](../../../../../400.deploy/500.deploy-oceanbase-database-community-edition/200.local-deployment/400.deploy-OceanBase-database-of-multi-node-cluster.md)。

<main id="notice" type='explain'>
  <h4>说明</h4>
  <p>社区版 OceanBase 数据库仅 V4.0.0 及以上版本支持 cgroup 完整功能。</p>
</main>

### 步骤三：与 OceanBase 数据库建立软链接

OceanBase 数据库安装成功后，需要建立 OceanBase 数据库软件的安装目录与 cgroup 系统目录的软链接。

1. 使用 `usercg` 用户登录到 OBServer 节点。

2. 手动建立 OceanBase 数据库软件的安装目录与 cgroup 系统目录的软链接。

   ```shell
   [usercg@xxx /home/usercg]$ cd /home/usercg/oceanbase/

   [usercg@xxx /home/usercg]
   $ ln -sf /sys/fs/cgroup/cpu/oceanbase/ cgroup
   ```

   其中：`/home/usercg/oceanbase/` 为 OceanBase 数据库软件的安装路径。

   执行成功后，结果如下所示。

   ```shell
   [usercg@xxx /home/usercg/oceanbase]
   $ll cgroup
   lrwxrwxrwx 1 usercg usercg 29 Dec  8 11:09 cgroup -> /sys/fs/cgroup/cpu/oceanbase/
   ```

3. 重新启动 observer 进程。

   您需要停止 observer 进程后再重新启动 observer 进程，具体操作请参见 [重启节点](../../../../../600.manage/100.cluster-management/300.common-cluster-operations/300.restart-a-node.md)。

   observer 进程在启动时，检测到之前已经建立的软链接，就会在 `/sys/fs/cgroup/cpu/oceanbase/` 目录下继续创建 OceanBase 数据库 cgroup 目录。

### 步骤四：开启 cgroup 功能

OceanBase 数据库通过集群级配置项 `enable_cgroup` 来控制 OBServer 是否开启 cgroup 功能。默认该功能为 `True`，表示已开启，如果未开启，您可以参考以下操作，开启 cgroup 功能。

1. 使用 `root` 用户登录集群的 `sys` 租户。

2. 执行以下命令，开启 cgroup 功能。

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=true;
   ```

   或者

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=1;
   ```

   或者

   ```sql
   obclient> ALTER SYSTEM SET enable_cgroup=ON;
   ```

## 后续操作

成功配置 cgroups 系统目录并开启 cgroup 功能后，在应急情况下，您可以通过各租户所在目录下的 `cpu.cfs_period_us`、`cpu.cfs_quota_us` 和 `cpu.shares` 三个文件来控制租户内的 CPU 占用。一般不建议使用该方式进行资源隔离。

推荐使用 cgroups 中的目录文件调用 `DBMS_RESOURCE_MANAGER` 系统包中的子程序 `CREATE_CONSUMER_GROUP` 创建的资源组，来进行用户级或 SQL 级的资源隔离。配置用户级资源隔离或 SQL 级资源隔离的详细操作，请参见以下信息：

* [配置用户级资源隔离](../200.resource-isolation-for-oracle-mode/200.resource-isolation-at-user-level-for-oracle-mode.md)

* [配置 SQL 级资源隔离](../200.resource-isolation-for-oracle-mode/300.resource-isolation-at-sql-level-for-oracle-mode.md)

## 相关文档

[清除 cgroup 配置](../200.resource-isolation-for-oracle-mode/800.clear-cgroup-configuration-for-oracle-mode.md)
