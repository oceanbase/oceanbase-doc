# 数据导入策略与最佳实践

在使用 OceanBase 数据库时，面对不同的数据导入需求，例如在即时导入和延时导入的场景下，您需要采取不同的数据导入策略。本文将详细介绍在 T+0 和 T+1 这两种场景下，如何将数据导入到 OceanBase 数据库，并提供最佳迁移实践的示例。

## 背景信息

T+0 即数据生成后立即（即时）进行处理和导入。这通常要求系统能够支持高并发的数据写入操作，并且能够保证数据实时性和即时可用性。

T+1 即数据在生产后的下一个工作日（“T+1”代表交易日加一天）进行处理和导入。相比 T+0，T+1 场景对实时性的要求较低。

## 导入基线数据

基线数据指特定时间点或条件下系统或项目的初始数据集。它代表了系统的起始状态或性能水平，用于未来变更的参照和比较。OceanBase 数据库提供以下导入基线数据的方案：

* 数据库到到数据库的在线迁移

  如果您的数据位于 OMS 支持的源端，我们建议您使用 OMS 导入数据。如果 OMS 不支持您的数据源，您可以使用 DataX 导入数据或者离线导入。

  * 关于 OMS 的详细介绍，参见 [OMS 使用文档](https://www.oceanbase.com/docs/oms-doc-cn)。

  * 关于 DataX 的详细介绍，参见 [DataX 使用文档](https://github.com/alibaba/DataX)。

* 文件到数据库的离线迁移

  如果 OMS 不支持您的数据源，您可以将数据导出为离线文件，然后使用 obloader、DataX 或 LOAD DATA 导入。其中，obloader 支持旁路导入，可以提升数据导入的性能。

  * 关于 obloader 的详细介绍，参见 [obloader 使用文档](https://www.oceanbase.com/docs/oceanbase-dumper-loader)。
  * 关于 DataX 的详细介绍，参见 [DataX 使用文档](https://github.com/alibaba/DataX)。
  * 关于 LOAD DATA LOCAL 的使用方法，参见 [LOAD DATA（Oracle 模式）](../../700.reference/500.sql-reference/100.sql-syntax/300.common-tenant-of-oracle-mode/900.sql-statement-of-oracle-mode/300.dcl-of-oracle-mode/1900.load-data-of-oracle-mode.md)和 [LOAD DATA（MySQL 模式）](../../700.reference/500.sql-reference/100.sql-syntax/200.common-tenant-of-mysql-mode/600.sql-statement-of-mysql-mode/5900.load-data-of-mysql-mode.md)。


## 导入增量数据

### T + 0 场景

T+0 即数据生成后立即（即时）进行处理和导入。您可以使用 OMS 的增量迁移功能将数据实时导入 OceanBase 数据库，也可以使用第三方集成工具，如 Flink 或 DataX 导入。其中，DataX 和 OMS 仅支持数据导入。Flink 支持实时数据计算加工，例如数据打宽和数据聚合，以及下游的存储、分析、服务。

### T + 1 场景

T+1 即数据在生产后的下一个工作日进行处理和导入。针对 T+1 数据导入场景，您可以采用批处理的方式来优化数据导入性能：

* 离线数据处理

  将一天产生的数据集中处理，并在非高峰时间批量导入到 OceanBase 数据库，从而减少对业务的影响。您可以使用 OMS 的增量迁移功能将数据在下一个工作日导入 OceanBase 数据库，也可以使用第三方集成工具，如 Flink 或 DataX 导入。例如，您可以使用 DataX 对业务数据库进行以天为单位的定时全量数据同步。

* 分区交换

  目标表是分区表，已经有数据了。例如每天是个分区。此时建一个目标表一模一样的表，但是没有分区。把数据插空表。此时交换数据，分区交换的命令。 

  直接向已存在数据的分区表中导入新数据时，性能可能较低。为了提高数据导入效率，您可以使用分区交换（Partition Exchange）功能。分区交换步骤如下：

  1. 创建一个与目标分区表结构完全一致的非分区临时表。
  2. 将待导入的数据插入到这个临时表中。
  3. 通过分区交换命令，将临时表中的数据和目标分区表的特定分区进行快速交换。

  更多信息，参考 [分区交换（MySQL 模式）](../../700.reference/300.database-object-management/100.manage-object-of-mysql-mode/300.manage-partitions-of-mysql-mode/1000.exchange-partition-of-mysql-mode.md) 和 [分区交换（Oracle 模式）](../../700.reference/300.database-object-management/200.manage-object-of-oracle-mode/200.manage-partitions-of-oracle-mode/1000.exchange-partition-of-oracle-mode.md)文档。

## 最佳实践

### 基于 DataX 和 Flink SQL 构建实时数仓

数据迁移方式：

* 历史数据

  使用 DataX 将历史数据导出为 CSV 文件后，再用 DataX 将 CSV 文件导入 OceanBase 数据库。在数据导入过程中，通过 DataX 导出 CSV 文件时，我们建议您在配置文件中使用 2881 端口直连 OceanBase 数据库。因为如果您使用 2883 端口，即 OBProxy 代理，可能将不同的命令分发到另外一台机器上。此时如果另外一台机器没有部署 DataX 且没有 CSV 文件则会找不到文件。

* 实时数据

  使用 Flink SQL 抽取实时数据，把数据写到 OceanBase 数据库中，实现毫秒级响应。经过测试，从数据产生到数据落到 OceanBase 数据库，可以在 1 秒内完成。

### 基于 Flink CDC 与 OceanBase 数据库构建实时数仓

本节介绍使用 Streaming OLAP 方案构建 OceanBase 数据库实时数仓。 因为 OceanBase 数据库支持行列混存的 HTAP 特性，可以在一套系统中支持交易处理和复杂分析。

![data-warehouse](https://obbusiness-private.oss-cn-shanghai.aliyuncs.com/doc/img/observer/ap/import.png)

通过 Flink CDC，把 MySQL 的全量数据和增量数据同步到 OceanBase 数据库，形成一个 ODS 数据层供下游订阅。订阅的同时读取数据做加工和打宽，然后写入下游的 OceanBase 数据库形成 DWD 数据层，通过聚合形成 DWS 数据层，此时 OceanBase 数据库可以为您提供查询服务和数据消费。在这个方案中，OceanBase 数据库替代了 KV 服务、分析服务 和 Kafka 等组件。此外，OceanBase 数据库的每一层都是可查、可更新和可修正的。因此，当某一层数据出现问题，您可以直接排查该层的表数据并进行修正，排查更高效。

以下示例中，我们需要将订单明细表进行聚合，然后写入 DWS 层的统计表中，再获取每个店铺每天的销售量。

1. 定义 OceanBase CDC 的数据源，它是一个来源于 oders 的表。

    ```sql
    CREATE TABLE dwd_orders (
    order_id  BIGINT,
    order_user_id  BIGINT,
    order_shop_id  BIGINT,
    order_product_id VARCHAR,
    order_fee DECIMAL(20,2),
    order_updated_time TIMESTAMP(3),
    pay_id BIGINT,
    pay_create_time TIMESTAMP(3),
    PRIMARY KEY (order id) NOT ENFORCED
    ) WITH (
    'connector' = 'oceanbase-cdc',
    'scan.startup.mode' = 'initial',
    'username' = 'user@test_tenant',
    'password' = 'pmsd',
    'tenant-name' = 'test_tenant',
    'database-name' = 'test_db',
    'table-name' = 'orders',
    'hostname' = '127.0.0.1',
    'port' = '2881',
    'rootserver-list' = '127.0.0.1:2882:2881',
    'logproxy.host' = '127.0.0.1',
    'logproxy.port' = '2983'
    );
    ```

2. 使用 FlinkCDC 统计店铺销售额，将 JDBC 的表写入 OceanBase 数据库的表中，形成了店铺指标的统计层。

    ```
    CREATE TABLE dws_shops (
    shop_id BIGINT,
    ds STRING,
    -- 当日完成支付总金额
    paid_buy_fee_sum DECIMAL(20, 2),
    PRIMARY KEY(shop_id,ds) NOT ENFORCED
    ) WITH (
    'connector' = 'jdbc',
    'url' = 'jdbc:mysql://localhost:3306/mydatabase',
    'table-name' = 'shops',
    'username' = 'user@test_tenant',
    'password' = 'pswd'
    );
    ```

3. 实时读取订单明细层（dwd_orders）的全量数据和增量数据，并进行实时聚合、加工。然后写入下游的 OceanBase 数据库中（dws_shops）。dwd_shops 表又可以由另一个 Flink 进行读取和加工，形成下一层的结果表。从而构建起整个流式数仓的分层。

    ```
    INSERT INTO dws_shops
    SELECT
      order_shop_id,
      date_format(pay_create_time, 'yyyyMMdd') AS ds,  -- 修正日期格式
      SUM(order_fee) AS paid_buy_fee_sum
    FROM dwd_orders
    WHERE pay_id IS NOT NULL AND order_fee IS NOT NULL
    GROUP BY order_shop_id, date_format(pay_create_time, 'yyyyMMdd');
    ```

## 注意事项

建议您在导入数据之后，做一次全量合并，以提升查询性能。

* 批量导入

  导入完成后合并一次。

* 实时导入

  在实时导入完成后合并。如果实时导入是无头无尾的持续导入，且没有人为干预的合并时机，由系统自动调度即可。

